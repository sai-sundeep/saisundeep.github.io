[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Regression/diamonds_regression.html",
    "href": "posts/Regression/diamonds_regression.html",
    "title": "Sai's ML blog",
    "section": "",
    "text": "#Import Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nsns.set_theme(style=\"darkgrid\")\n\n\ndiamonds = sns.load_dataset('diamonds')\nprint(diamonds.shape)\nprint(diamonds.describe())\nprint(diamonds.head(10))\n\n(53940, 10)\n              carat         depth         table         price             x  \\\ncount  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \nmean       0.797940     61.749405     57.457184   3932.799722      5.731157   \nstd        0.474011      1.432621      2.234491   3989.439738      1.121761   \nmin        0.200000     43.000000     43.000000    326.000000      0.000000   \n25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \nmax        5.010000     79.000000     95.000000  18823.000000     10.740000   \n\n                  y             z  \ncount  53940.000000  53940.000000  \nmean       5.734526      3.538734  \nstd        1.142135      0.705699  \nmin        0.000000      0.000000  \n25%        4.720000      2.910000  \n50%        5.710000      3.530000  \n75%        6.540000      4.040000  \nmax       58.900000     31.800000  \n   carat        cut color clarity  depth  table  price     x     y     z\n0   0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n1   0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n2   0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n3   0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n4   0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n5   0.24  Very Good     J    VVS2   62.8   57.0    336  3.94  3.96  2.48\n6   0.24  Very Good     I    VVS1   62.3   57.0    336  3.95  3.98  2.47\n7   0.26  Very Good     H     SI1   61.9   55.0    337  4.07  4.11  2.53\n8   0.22       Fair     E     VS2   65.1   61.0    337  3.87  3.78  2.49\n9   0.23  Very Good     H     VS1   59.4   61.0    338  4.00  4.05  2.39\n\n\n\nsns.histplot(data=diamonds, x='price', kde=True)\nplt.title('Diamonds Dataset - Price Distribution')\nplt.ylabel(\"# of sales\")\nplt.xlabel(\"Price\")\nplt.grid('both')\nplt.show()\n\n\n\n\n\nsns.countplot(data=diamonds, y='cut', order=diamonds['cut'].value_counts().index,\n              palette=sns.color_palette('flare', 10))\nplt.title('Diamonds Dataset - sales by cut type')\nplt.xlabel('# of Sales')\nplt.ylabel('Cut Type')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nsns.countplot(data=diamonds, y='clarity', \n              order = diamonds['clarity'].value_counts(ascending=True).index,\n              palette=sns.color_palette('flare', 10))\nplt.xlabel('# of Sales')\nplt.ylabel('Clarity Type')\nplt.title('Diamonds Dataset - Sales by Clarity Type')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nsns.countplot(data=diamonds, \n              x = 'color', \n              order = diamonds['color'].value_counts(ascending=False).index,\n              palette=sns.color_palette('flare', 10))\nplt.ylabel('# of Sales')\nplt.xlabel('Color')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nsns.kdeplot(diamonds, x='price', hue='color', common_norm=False)\nplt.show()\n\n\n\n\n\ndiamonds['clarity'].value_counts(ascending=False)\n\nclarity\nSI1     13065\nVS2     12258\nSI2      9194\nVS1      8171\nVVS2     5066\nVVS1     3655\nIF       1790\nI1        741\nName: count, dtype: int64\n\n\n\ndiamonds['color'].value_counts(ascending=False)\n\ncolor\nG    11292\nE     9797\nF     9542\nH     8304\nD     6775\nI     5422\nJ     2808\nName: count, dtype: int64\n\n\n\ndiamonds['cut'].value_counts(ascending=False)\n\ncut\nIdeal        21551\nPremium      13791\nVery Good    12082\nGood          4906\nFair          1610\nName: count, dtype: int64\n\n\n\n# Analyzing distribution of numeric features with histogram plot\nsns.set_theme(style=\"whitegrid\")\ndiamonds.hist(bins=50, figsize=(12, 8))\nplt.show()\n\n\n\n\n\ncorr_matrix = diamonds.select_dtypes(np.number).corr()\n\n\ncorr_matrix['price'].sort_values(ascending=False)\n\nprice    1.000000\ncarat    0.921591\nx        0.884435\ny        0.865421\nz        0.861249\ntable    0.127134\ndepth   -0.010647\nName: price, dtype: float64\n\n\n\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(diamonds[['price', 'carat', 'x', 'y', 'z', 'table', 'depth']], figsize=(15, 10))\nplt.show()\n\n\n\n\n\nfrom prettytable import PrettyTable\ndef pretty_printing_function(correlation_name, row_values, column_names):\n    summary_table = PrettyTable()\n    summary_table.title = f\"{correlation_name} Correlation Matrix for the tute1 dataset\"\n    column_names = [f'Feature({chr(0x2193)})/({chr(0x2192)})'] + column_names\n    summary_table.field_names = column_names\n    for i in range(len(row_values)):\n        row_index = column_names[i+1]\n        row_values[i] = [row_index] + row_values[i]\n        summary_table.add_row(row_values[i])\n    print(summary_table)\n\n\ndef calc_pearson_corr(x, y, N):\n    numerator_sum = 0.0; denomnator1_sum = 0.0; denomnator2_sum = 0.0\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    for i in range(N):\n        x_diff = x[i] - x_mean\n        y_diff = y[i] - y_mean\n        numerator_sum += (x_diff * y_diff)\n        denomnator1_sum += np.power(x_diff, 2)\n        denomnator2_sum += np.power(y_diff, 2)\n    pearson_corrcoef = numerator_sum/(np.sqrt(denomnator1_sum)*np.sqrt(denomnator2_sum))\n    return round(pearson_corrcoef, 2)\n\n\ndef calc_partial_corr(x, y, z):\n    r_xy = calc_pearson_corr(x, y, len(diamonds))\n    r_xz = calc_pearson_corr(x, z, len(diamonds))\n    r_yz = calc_pearson_corr(y, z, len(diamonds))\n    partial_corr = (r_xy - (r_xz*r_yz)) / (np.sqrt(1 - r_xz**2) * np.sqrt(1 - r_yz**2))\n    return round(partial_corr, 2)\n\n\ndiamonds_numeric = diamonds.select_dtypes(np.number)\ndef calc_partial_correlation():\n    summary_df = pd.DataFrame(columns = diamonds_numeric.columns, index = diamonds_numeric.columns)\n    for col1 in diamonds_numeric.columns:\n        for col2 in diamonds_numeric.columns:\n            if col1 == col2:\n                summary_df.loc[col1, col2] = 1.0\n            else:\n                other_columns = list(set(diamonds_numeric.columns) - set([col1, col2]))\n                for col3 in other_columns:\n                    summary_df.loc[col1, col2] = calc_partial_corr(diamonds_numeric[col1], diamonds_numeric[col2], diamonds_numeric[col3])\n    pretty_printing_function(\"Partial\", summary_df.values.tolist(), column_names=list(summary_df.columns))\n    return summary_df\n\ncalc_partial_correlation()\n\n+---------------------------------------------------------------------+\n|           Partial Correlation Matrix for the tute1 dataset          |\n+----------------+-------+-------+-------+-------+------+------+------+\n| Feature(↓)/(→) | carat | depth | table | price |  x   |  y   |  z   |\n+----------------+-------+-------+-------+-------+------+------+------+\n|     carat      |  1.0  |  0.09 |  0.2  |  0.92 | 0.98 | 0.95 | 0.95 |\n|     depth      |  0.09 |  1.0  | -0.32 |  0.03 | 0.03 | 0.03 | 0.14 |\n|     table      |  0.2  | -0.32 |  1.0  |  0.13 | 0.2  | 0.18 | 0.19 |\n|     price      |  0.92 |  0.03 |  0.13 |  1.0  | 0.88 | 0.87 | 0.86 |\n|       x        |  0.98 |  0.03 |  0.2  |  0.88 | 1.0  | 0.97 | 0.98 |\n|       y        |  0.95 |  0.03 |  0.18 |  0.87 | 0.97 | 1.0  | 0.96 |\n|       z        |  0.95 |  0.14 |  0.19 |  0.86 | 0.98 | 0.96 | 1.0  |\n+----------------+-------+-------+-------+-------+------+------+------+\n\n\n\n\n\n\n\n\n\ncarat\ndepth\ntable\nprice\nx\ny\nz\n\n\n\n\ncarat\n1.0\n0.09\n0.2\n0.92\n0.98\n0.95\n0.95\n\n\ndepth\n0.09\n1.0\n-0.32\n0.03\n0.03\n0.03\n0.14\n\n\ntable\n0.2\n-0.32\n1.0\n0.13\n0.2\n0.18\n0.19\n\n\nprice\n0.92\n0.03\n0.13\n1.0\n0.88\n0.87\n0.86\n\n\nx\n0.98\n0.03\n0.2\n0.88\n1.0\n0.97\n0.98\n\n\ny\n0.95\n0.03\n0.18\n0.87\n0.97\n1.0\n0.96\n\n\nz\n0.95\n0.14\n0.19\n0.86\n0.98\n0.96\n1.0\n\n\n\n\n\n\n\n\ndiamonds.plot(kind=\"scatter\", x=\"price\", y=\"carat\",\n             alpha=0.07, grid=True)\nplt.show()\n\n\n\n\n\ndiamonds.shape\ndiamonds.head(10)\n\n\n\n\n\n\n\n\ncarat\ncut\ncolor\nclarity\ndepth\ntable\nprice\nx\ny\nz\n\n\n\n\n0\n0.23\nIdeal\nE\nSI2\n61.5\n55.0\n326\n3.95\n3.98\n2.43\n\n\n1\n0.21\nPremium\nE\nSI1\n59.8\n61.0\n326\n3.89\n3.84\n2.31\n\n\n2\n0.23\nGood\nE\nVS1\n56.9\n65.0\n327\n4.05\n4.07\n2.31\n\n\n3\n0.29\nPremium\nI\nVS2\n62.4\n58.0\n334\n4.20\n4.23\n2.63\n\n\n4\n0.31\nGood\nJ\nSI2\n63.3\n58.0\n335\n4.34\n4.35\n2.75\n\n\n5\n0.24\nVery Good\nJ\nVVS2\n62.8\n57.0\n336\n3.94\n3.96\n2.48\n\n\n6\n0.24\nVery Good\nI\nVVS1\n62.3\n57.0\n336\n3.95\n3.98\n2.47\n\n\n7\n0.26\nVery Good\nH\nSI1\n61.9\n55.0\n337\n4.07\n4.11\n2.53\n\n\n8\n0.22\nFair\nE\nVS2\n65.1\n61.0\n337\n3.87\n3.78\n2.49\n\n\n9\n0.23\nVery Good\nH\nVS1\n59.4\n61.0\n338\n4.00\n4.05\n2.39\n\n\n\n\n\n\n\n\n# One-hot encode the categorical variabled before feeding into linear model\nfrom sklearn.preprocessing import OneHotEncoder\n\ndiamonds_cut = diamonds[['cut']]\n\nenc = OneHotEncoder(handle_unknown='ignore')\ndiamonds_cuts_onehot = enc.fit_transform(diamonds_cut)\n\n\nenc.categories_\n\n[array(['Fair', 'Good', 'Ideal', 'Premium', 'Very Good'], dtype=object)]\n\n\n\nenc.get_feature_names_out()\n\narray(['cut_Fair', 'cut_Good', 'cut_Ideal', 'cut_Premium',\n       'cut_Very Good'], dtype=object)\n\n\n\ndiamonds_cuts_onehot.toarray()\n\narray([[0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       ...,\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0.]])\n\n\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\n\ncategorical_features = ['cut', 'color', 'clarity']\nnumeric_features = ['x', 'y', 'z', 'carat', 'depth', 'table']\n\nnumeric_transformer = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n\npreprocessor = ColumnTransformer(\n    [\n        ('num', numeric_transformer, numeric_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n    ],\n    verbose_feature_names_out=False\n)\n\n\ndiamonds_features, diamonds_price = diamonds.loc[:, diamonds.columns != 'price'], diamonds['price']\n\n\ndiamonds_features.shape\n\n(53940, 9)\n\n\n\ndiamonds_price.shape\n\n(53940,)\n\n\n\ndiamonds_features.head()\n\n\n\n\n\n\n\n\ncarat\ncut\ncolor\nclarity\ndepth\ntable\nx\ny\nz\n\n\n\n\n0\n0.23\nIdeal\nE\nSI2\n61.5\n55.0\n3.95\n3.98\n2.43\n\n\n1\n0.21\nPremium\nE\nSI1\n59.8\n61.0\n3.89\n3.84\n2.31\n\n\n2\n0.23\nGood\nE\nVS1\n56.9\n65.0\n4.05\n4.07\n2.31\n\n\n3\n0.29\nPremium\nI\nVS2\n62.4\n58.0\n4.20\n4.23\n2.63\n\n\n4\n0.31\nGood\nJ\nSI2\n63.3\n58.0\n4.34\n4.35\n2.75\n\n\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\ndiamonds_features_train, diamonds_features_test, diamonds_price_train, diamonds_price_test = train_test_split(diamonds_features, diamonds_price, test_size=0.25)\n\n#print(diamonds_features_train.head(), diamonds_price_train.head())\n\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = make_pipeline(preprocessor, LinearRegression())\nlin_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('linearregression', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('linearregression', LinearRegression())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)LinearRegressionLinearRegression()\n\n\n\nlin_reg[:-1].get_feature_names_out()\n\narray(['x', 'y', 'z', 'carat', 'depth', 'table', 'cut_Fair', 'cut_Good',\n       'cut_Ideal', 'cut_Premium', 'cut_Very Good', 'color_D', 'color_E',\n       'color_F', 'color_G', 'color_H', 'color_I', 'color_J',\n       'clarity_I1', 'clarity_IF', 'clarity_SI1', 'clarity_SI2',\n       'clarity_VS1', 'clarity_VS2', 'clarity_VVS1', 'clarity_VVS2'],\n      dtype=object)\n\n\n\nlin_reg_input_features = lin_reg[:-1].get_feature_names_out()\npd.Series(lin_reg[-1].coef_.ravel(), index=lin_reg_input_features).plot.bar()\nplt.tight_layout()\n\n\n\n\n\ndiamonds_price_predictor = lin_reg.predict(diamonds_features_test)\n\n\nlin_reg[-1].coef_\n\narray([-1.18206223e+03, -2.37825898e+00, -3.92994580e+01,  5.39684709e+03,\n       -8.97161459e+01, -5.77167234e+01,  1.98788030e+15,  1.98788030e+15,\n        1.98788030e+15,  1.98788030e+15,  1.98788030e+15,  2.52457342e+15,\n        2.52457342e+15,  2.52457342e+15,  2.52457342e+15,  2.52457342e+15,\n        2.52457342e+15,  2.52457342e+15,  2.20058043e+15,  2.20058043e+15,\n        2.20058043e+15,  2.20058043e+15,  2.20058043e+15,  2.20058043e+15,\n        2.20058043e+15,  2.20058043e+15])\n\n\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, diamonds_price_predictor))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, diamonds_price_predictor))\n\nMean Squared Error: 1318797.39\nCoefficient of Determination: 0.92\n\n\n\nfrom sklearn.linear_model import SGDRegressor\n\nsgd_reg = make_pipeline(preprocessor, SGDRegressor(max_iter=1000, tol=1e-5, penalty=None, eta0=0.01, n_iter_no_change=100, random_state=42))\nsgd_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('sgdregressor',\n                 SGDRegressor(n_iter_no_change=100, penalty=None,\n                              random_state=42, tol=1e-05))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('sgdregressor',\n                 SGDRegressor(n_iter_no_change=100, penalty=None,\n                              random_state=42, tol=1e-05))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)SGDRegressorSGDRegressor(n_iter_no_change=100, penalty=None, random_state=42, tol=1e-05)\n\n\n\nprice_predictor_sgd = sgd_reg.predict(diamonds_features_test)\n\n\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, price_predictor_sgd))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, price_predictor_sgd))\n\nMean Squared Error: 1319437.35\nCoefficient of Determination: 0.92\n\n\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr_reg = make_pipeline(preprocessor, RandomForestRegressor())\nrfr_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('randomforestregressor', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)RandomForestRegressorRandomForestRegressor()\n\n\n\nprice_predictor_rfr = rfr_reg.predict(diamonds_features_test)\n\n\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, price_predictor_rfr))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, price_predictor_rfr))\n\nMean Squared Error: 319594.77\nCoefficient of Determination: 0.98\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Clustering/index.html",
    "href": "posts/Clustering/index.html",
    "title": "Clustering",
    "section": "",
    "text": "This is a post with executable code.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Classification/fashion_mnist_classification.html",
    "href": "posts/Classification/fashion_mnist_classification.html",
    "title": "Multiclass Classification on Fashion MNIST Dataset",
    "section": "",
    "text": "In this blog we will be performing multiclass classification on the Fashion MNIST dataset. The dataset contains 60,000 images for training and 10,000 images for validation of 10 different types of fashion products. Multiclass classification is a classification task with more than two classes. Each sample can only be labeled as one class. For example, in the context of fashion-mnist images, each image can be of either a shirt, a sneaker, or a trouser. Each image is one sample and is labeled as one of the 10 possible classes. Multiclass classification makes the assumption that each sample is assigned to one and only one label - one sample cannot, for example, be both a shirt and a coat.\nWe will be performing the following tasks in this blog - * Import, analyze, and visualize the fashion-mnist dataset. * Prepare the data for classification + Principal Component Analysis + Hyperparameter Tuning with Randomized Search * Train a RandomForestClassifier and visualize its performance metrics * Observations and Conclusion\nLet us begin by importing a few packages and loading the data into a pandas dataframe.\n\n1. Import, analyze, and visualize the fashion-mnist dataset.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(category=UserWarning, action='ignore')\n\n\n# Load the train and test datasets\nfmnist_train_df = pd.read_csv(\"data/fashion_mnist_train.csv\")\nfmnist_test_df = pd.read_csv(\"data/fashion_mnist_test.csv\")\n\n\nprint(f'Train Set Dimensions - {fmnist_train_df.shape}')\nprint(f'Test Set Dimensions - {fmnist_test_df.shape}')\n\nTrain Set Dimensions - (60000, 785)\nTest Set Dimensions - (10000, 785)\n\n\nLet us print a few records from the training set and see how the data looks like.\n\nfmnist_train_df.head(10)\n\n\n\n\n\n\n\n\nlabel\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\npixel9\n...\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\npixel784\n\n\n\n\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n9\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n6\n0\n0\n0\n0\n0\n0\n0\n5\n0\n...\n0\n0\n0\n30\n43\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n1\n2\n0\n0\n0\n0\n...\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n4\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n5\n4\n0\n0\n0\n5\n4\n5\n5\n3\n5\n...\n7\n8\n7\n4\n3\n7\n5\n0\n0\n0\n\n\n6\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n14\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n7\n5\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n8\n4\n0\n0\n0\n0\n0\n0\n3\n2\n0\n...\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n9\n8\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n203\n214\n166\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n10 rows × 785 columns\n\n\n\nWe can see that most of the data is 0 with few values here and there. That is because each row is a 28 * 28 pixel image flattened into an [784,] array. Each element con contain a value between 0 and 255. Furthermore, the target feature named as label is having values from 0 to 9. We will have to process this column a little bit, to make more sense in the context of fashion products that we need to predict. We will see how to do that in just a bit, but first, let us try to reshape the images into 28 * 28 and try to visualize them using the matplotlib subplots.\n\n# Visualize the Images in the Dataset\nlabels_list = list(fmnist_train_df['label'].unique())\nlabels_list.sort()\nfig, axs = plt.subplots(10, 10, figsize=(12, 12), layout='constrained')\nfor i in range(0, 10):\n    class_df = fmnist_train_df[fmnist_train_df['label'] == labels_list[i]]\n    for j in range(0, 10):\n        sample_image = class_df.iloc[j, 1:].values.reshape(28, 28)\n        axs[i][j].imshow(sample_image, cmap='Blues')\n        axs[i][j].grid(False)\n        if j == 0: axs[i][j].set_ylabel(f\"Class {labels_list[i]}\")\nplt.grid(False)\nplt.show()\n\n\n\n\nWe can see from the above plot different kinds of fashion products in the dataset. An obvious difficulty our multiclass classification algorith may face is the close resemblance of three different classes - class 0, class 2, and class 6. Fashion MNIST labels these classes as T-shirt/Top, Pullover, and Shirt respectively. To make target classes clear for us going forward, let us write a helper function that maps, the respective class number to its corresponding label.\n\n# Create more descriptive labels\ndef label_mapper(input):\n    match input:\n        case 0:\n            return 'T-shirt/top'\n        case 1:\n            return 'Trouser'\n        case 2:\n            return 'Pullover'\n        case 3:\n            return 'Dress'\n        case 4:\n            return 'Coat'\n        case 5:\n            return 'Sandal'\n        case 6:\n            return 'Shirt'\n        case 7:\n            return 'Sneaker'\n        case 8:\n            return 'Bag'\n        case 9:\n            return 'Ankle boot'\n\nfmnist_train_df['label'] = fmnist_train_df['label'].apply(lambda x:label_mapper(x))\nfmnist_test_df['label'] = fmnist_test_df['label'].apply(lambda x:label_mapper(x))\n\nLet us visualize if these changes took effect in the label column by printing a few values.\n\nfmnist_train_df['label'].head(10)\n\n0       Pullover\n1     Ankle boot\n2          Shirt\n3    T-shirt/top\n4          Dress\n5           Coat\n6           Coat\n7         Sandal\n8           Coat\n9            Bag\nName: label, dtype: object\n\n\n\n\n2. Prepare the data for classification\n\n# Split the data into predictors (features) and target (label) in train and test sets\nX_train = fmnist_train_df.iloc[:, 1:]\nX_test = fmnist_test_df.iloc[:, 1:]\ny_train = fmnist_train_df['label'].values\ny_test = fmnist_test_df['label'].values\n\nWe already have the training and test set split for us. So let us just separate the predictor and target variables into matrix X (actually pandas DataFrame) and vector y (a pandas series) from training and test set. We will beusing the X_train and y_train to fit a classification model. We will then be using y_test to make prediction on samples that are unseen by the trained multiclass classification model. Finally, we will use y_test to evaluate our model.\nBefore we get ahead to the model, we will need to do some preprocessing. Image classification is a computationally expensive task and training 60,000 images each of 28*28 pixels can take significant of computing resources and training time. Furthermore, we do not have to invest as much resources, because very often only a portion of the images are useful for training. Take for example, in the below image of a pullover, a RandomForestClassifier trained on training data of 1000 samples, showing the important pixels in the image.\n\nfrom sklearn.ensemble import RandomForestClassifier\nrnd_clf = RandomForestClassifier(n_estimators=100)\nrnd_clf.fit(X_train[:1000], y_train[:1000])\n\nheatmap_image = rnd_clf.feature_importances_.reshape(28, 28)\nplt.imshow(heatmap_image, cmap=\"hot\")\ncbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(),\n                           rnd_clf.feature_importances_.max()])\ncbar.ax.set_yticklabels(['Not important', 'Very important'], fontsize=14)\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n2.1 Principal Component Analysis\nAn amazingly helpful strategy to reduce the number of features in the dataset is Principal Component Analysis (PCA). PCA is a dimensionality reduction technique, that transforms the original feature space into a reduced feature space of orthogonal components such that the transformed feature space retains as much variance as possible from the original space. This transformed coordinate system for the principal components. The first principal component can equivalently be defined as a direction that maximizes the variance of the projected data. The i-th principal component can be taken as a direction orthogonal to the first i-1 principal components that maximizes the variance of the projected data.\nIt can be shown that the principal components are eigenvectors of the data’s covariance matrix. Thus, the principal components are often computed by eigendecomposition of the data covariance matrix or singular value decomposition (SVD) of the data matrix. In SVD, we will start from the original data matrix X which has samples in rows and measured variables in columns. The SVD decomposition breaks this matrix X into three matrices -\n\\[ X(n × p) = U_(n × p) * D_(p × p) * V^T_(p × p) \\]\nWhere, - X contains the original data - The columns of U are vectors giving the principal axes. These define the new coordinate system. - The scores can be obtained by XV; scores are the projections of the data on the principal axes. - D is a diagonal matrix, which means all non-diagonal elements are zero. The diagonal contains positive values sorted from largest to smallest. These are called the singular values. - The columns of V are the PCA loadings\nIn addition, U and V are semi-orthogonal matrices, which means that when pre-multiplied by their transpose one gets the identity matrix:\n\\[ U^T * U = I \\] \\[ V^T * V = I \\]\nTo reduce the number of features from 784, We will perform PCA on the fashion-mnist dataset. Before we do that we need to scale our data. PCA assumes that data is normally distributed and is sensitive to the variance of variables, so we scale the data to ensure all variables are on the same scale. This also improves the performance of the algorithm and its prediction accuracy.\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\npca = PCA()\npca.fit(X_train)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nncomponents_95_variance = np.argmax(cumulative_variance &gt;= 0.95) + 1\nprint(f\"Number of Components needed for 95% Variance - {ncomponents_95_variance}\")\n\nNumber of Components needed for 95% Variance - 256\n\n\nTo above step, creates an instance of StandardScaler and fits and transforms the trianing images. The test images are then scaled. The next part performs a full PCA analysis on the training set and calculates the cumulative explained variance - this is the sum of variance by individual principal components. As we can see, to retain 95% of the variance in the dataset, we need just 256 features. It is now computationally manageable for us to train the classifier using a subset of features. One drawback of PCA however is that, it does not tell us which features to retain and which to drop. That is why we will rely on a powerful classifier like RandomForestClassifier, which supports feature sampling.\nBefore that, let me show you a very useful plot that will allow you to visualize the number of components versus the explained variance. This plot allows you to see, how many components you need to retain certain amount of variance in the reduced feature space. For example, in the below plot you can see that, we need only 150 features to explain 91% of the variance in the data. We can build a pretty good model with that variance and strong classifier.\n\nplt.figure(figsize=(8, 6))\nplt.plot(np.arange(1, len(pca.explained_variance_ratio_)+1, 1), np.cumsum(pca.explained_variance_ratio_)*100)\nplt.plot([150, 150], [0, 91], \"k:\")\nplt.plot([0, 150], [91, 91], \"r:\")\nplt.plot(150, 91, \"ro\")\nplt.text(x=-20, y=91, s='91%', color='red', weight='bold', ha='center', va='center')\nplt.text(x=150, y=-3.5, s='150', color='blue', weight='bold', ha='center', va='center')\nplt.axis([0, 600, 0, 100])\nplt.title(\"Fashion MNIST PCA Analysis - Explained Variance vs # of Components\")\nplt.xlabel(\"Number of Components\", weight='bold')\nplt.ylabel(\"Explained Cumulative Variance (%)\", weight='bold')\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.grid(which='major', linestyle='-')\nplt.show()\n\n\n\n\n\n\n2.2 Hyperparameter Tuning with Randomized Search\nWe can also use hyperparameter tuning to search for best parameters. This is called Hyperparameter Optimization or Hyperparameter Tuning. Scikit learn’s GridSearchCV or RandomizedSearchCV can help with hyperparameter tuning. We can get the best values for number of components from principal component analysis and number of estimators from RandomForestClassifier using these methods. RandomizedSearchCV is preferred over GridSearchCV when there are many parameter values to try out. In contrast to GridSearchCV, RandomizedSearchCV tries not all parameter values but rather a fixed number of parameter settings sampled from the specified distributions making the search for best parameters quicker.\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\n\npreprocess_pipeline = make_pipeline(PCA(random_state=5805), RandomForestClassifier(random_state=5805))\nparams_distribution = {\n    \"pca__n_components\": np.arange(50, 250), \n    \"randomforestclassifier__n_estimators\": np.arange(100, 400)\n}\nrandomized_search = RandomizedSearchCV(preprocess_pipeline, params_distribution, n_iter=10, cv=3, random_state=5805)\nrandomized_search.fit(X_train[:1000], y_train[:1000])\n\nRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('pca', PCA(random_state=5805)),\n                                             ('randomforestclassifier',\n                                              RandomForestClassifier(random_state=5805))]),\n                   param_distributions={'pca__n_components': array([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n        63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n        76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,...\n       308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n       321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n       334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n       347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359,\n       360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n       373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n       386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n       399])},\n                   random_state=5805)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('pca', PCA(random_state=5805)),\n                                             ('randomforestclassifier',\n                                              RandomForestClassifier(random_state=5805))]),\n                   param_distributions={'pca__n_components': array([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n        63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n        76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,...\n       308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n       321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n       334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n       347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359,\n       360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n       373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n       386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n       399])},\n                   random_state=5805)estimator: PipelinePipeline(steps=[('pca', PCA(random_state=5805)),\n                ('randomforestclassifier',\n                 RandomForestClassifier(random_state=5805))])PCAPCA(random_state=5805)RandomForestClassifierRandomForestClassifier(random_state=5805)\n\n\nWe can then use the best_params_ attribute from the model to see the parameters that give best results. Note that above I have performed the search on 1000 training instances. Fell free to try and train on more instances. As you can see below, the number of estimators (desision tree classifiers) required by RandomForestClassifier are 197 and number of features are 234.\n\nrandomized_search.best_params_\n\n{'randomforestclassifier__n_estimators': 197, 'pca__n_components': 234}\n\n\n\n\n3. Train a RandomForestClassifier and visualize its performance metrics\nUsing this analysis and hyperparameters, let us now proceed to train the classifier. We will use the n_estimators in RandomForestClassifier to be 197 and fit method to train the classifier. We will use the predict method of the classifier to get the predictions the classifier will make on the dataset. Let us store them in y_pred which we can later use for evaluating the classifier.\n\n# Perform PCA Transform with above n_components\npca = PCA(n_components=234, random_state=5805)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\n\n\n# Train classifier\nrandom_forest_classifier = RandomForestClassifier(n_estimators=197, random_state=5805)\nrandom_forest_classifier.fit(X_train, y_train)\ny_pred = random_forest_classifier.predict(X_test)\n\nNow that we have trained our model and obtained the predictions from it for the test set. It is time to evaluate its performance. A very useful tool for evaluating the multiclass classification model is the classification_report from the sklearn metrics module. It gives us the precision, recall, and f1-score for each class. It also gives the overall f1-score of the classifier and a few other metrics we will discuss in just a second. We can extract the classification_report as follows -\n\nfrom sklearn.metrics import classification_report\n\nprint(\n    f\"Classification report for {random_forest_classifier}:\\n\"\n    f\"{classification_report(y_test, y_pred)}\\n\"\n)\n\nClassification report for RandomForestClassifier(n_estimators=197, random_state=5805):\n              precision    recall  f1-score   support\n\n  Ankle boot       0.89      0.94      0.92      1000\n         Bag       0.93      0.97      0.95      1000\n        Coat       0.79      0.87      0.83      1000\n       Dress       0.88      0.92      0.90      1000\n    Pullover       0.80      0.79      0.80      1000\n      Sandal       0.93      0.90      0.92      1000\n       Shirt       0.74      0.57      0.65      1000\n     Sneaker       0.90      0.88      0.89      1000\n T-shirt/top       0.79      0.84      0.82      1000\n     Trouser       0.99      0.96      0.98      1000\n\n    accuracy                           0.87     10000\n   macro avg       0.86      0.87      0.86     10000\nweighted avg       0.86      0.87      0.86     10000\n\n\nSo how do we read this classification report? Let us first define each of the metrics.\n\nPrecision - In a multi-class classification task, the precision for a class is the number of true positives (i.e. the number of images correctly labelled as belonging to the positive class) divided by the total number of elements labelled as belonging to the positive class (i.e. the sum of true positives and false positives, which are images incorrectly labelled as belonging to the class).\n\n\\[ {\\displaystyle \\mathrm {PPV} ={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FP} }}=1-\\mathrm {FDR} } \\]\n\nRecall - Recall in this context is defined as the number of true positives divided by the total number of images that actually belong to the positive class (i.e. the sum of true positives and false negatives, which are images which were not labelled as belonging to the positive class but should have been).\n\n\\[ {\\displaystyle \\mathrm {TPR} ={\\frac {\\mathrm {TP} }{\\mathrm {P} }}={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }}=1-\\mathrm {FNR} } \\]\n\nPrecision and recall are not particularly useful metrics when used in isolation. The need to be used in conjunction with other metrics to obtain a comprehensive evaluation of the model’s performance. For instance, A trivial way to have perfect precision is to create a classifier that always makes negative predictions, except for one single positive prediction on the instance it’s most confident about. If this one prediction is correct, then the classifier has 100% precision. Such a classifer would not be any helpful. Likewise, it is possible to have perfect recall by simply retrieving every single item. - F1-score and Accuracy - The F1-score is a metric that combines precision and recall to obtain a balanced classification model. The F1 score favors classifiers that have similar precision and recall. It is calculated as the harmonic mean of precision and recall. Accuracy is another metric that measures the proportion of correct predictions made by the model.\n\nF1 Score \\[ {\\displaystyle \\mathrm {F} _{1}=2\\times {\\frac {\\mathrm {PPV} \\times \\mathrm {TPR} }{\\mathrm {PPV} +\\mathrm {TPR} }}={\\frac {2\\mathrm {TP} }{2\\mathrm {TP} +\\mathrm {FP} +\\mathrm {FN} }}} \\]\nAccuracy (ACC) \\[ {\\displaystyle \\mathrm {ACC} ={\\frac {\\mathrm {TP} +\\mathrm {TN} }{\\mathrm {P} +\\mathrm {N} }}={\\frac {\\mathrm {TP} +\\mathrm {TN} }{\\mathrm {TP} +\\mathrm {TN} +\\mathrm {FP} +\\mathrm {FN} }}} \\]\nAnathor important tool to evaluate the classifier is the Confusion Matrix, in the multi-class classification context, it gives the actual predictions in horizontal rows and predicted classes in vertical columns. We can use the ConfusionMatrixDisplay from scikit learn’s metrics module to plot the confusion matrix for the classifier.\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\ndisp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\ndisp.figure_.suptitle(\"Confusion Matrix\")\nprint(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\nplt.grid(False)\nplt.xticks(rotation=60)\nplt.show()\n\nConfusion matrix:\n[[944   0   0   0   0  20   0  36   0   0]\n [  0 975   4   4   4   2   7   2   2   0]\n [  0   8 868  24  51   0  49   0   0   0]\n [  0   3  24 922   8   0  14   0  24   5]\n [  0  13 117  10 788   1  57   0  14   0]\n [ 36   6   0   0   0 902   0  56   0   0]\n [  0  25  82  23 113   0 575   0 182   0]\n [ 76   1   0   0   0  41   0 882   0   0]\n [  1  20   4  40  13   5  71   1 844   1]\n [  1   1   3  20   4   0   4   0   3 964]]\n\n\n\n\n\nWe can normalize the confusion matrix by dividing each value by the total number of images in the corresponding (true) class (i.e., divide by the row’s sum). This helps us to see where the model has misclassfied the images of a given class as belonging to different class.\n\n# Plot the normalized confused matrix.\nConfusionMatrixDisplay.from_predictions(y_test, y_pred, normalize='true', values_format=\".0%\")\nplt.grid()\nplt.title(\"Normalized Confusion Matrix\")\nplt.xticks(rotation=60)\nplt.show()\n\n\n\n\n\n\n4. Observations and Conclusion\nLooking at the classification report, ROC Curve, and confusion matrix, we can make following observations -\nThe precision for “coat”, “shirt”, “pullover”, and “T-shirt/top” is very low. This tells us that the model is predicting many False Positives for these classes. This is because these four classes are closely resembling one another. The classifier is unable to tell apart confidently a “coat” from a “shirt” and is resulting in many false positives and low precision. One way to improve the model precision for these labels is to increase the number of samples so that model can learn the subtle differences to tell apart each of these classes.\nThe recall for shirt is very low 57%. This tells that many images of shirt have been misclassified as belonging to a different class. Looking at the normalized confusin matrix, we can see that 18% of shirts have been misclassified as T-Shirt/Top, 11% of the shirts have been misclassified as pullover and 8% as Coats. We can see the same issue with images of pullover and coat, they have been misclassified as these other similar looking products.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Series",
    "section": "",
    "text": "Welcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2023\n\n\nSai Sundee Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nProbability Theory and Random Variables\n\n\n\n\n\n\n\nprobability theory\n\n\ncode\n\n\nanalysis\n\n\nrandom variables\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nClustering\n\n\n\n\n\n\n\nclustering\n\n\ncode\n\n\nscatter plot\n\n\nanalysis\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nLinear and Non-Linear Regression\n\n\n\n\n\n\n\nregression\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\npolynomial regression\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nAnomaly Detection\n\n\n\n\n\n\n\nanomaly detection\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nMulticlass Classification on Fashion MNIST Dataset\n\n\n\n\n\n\n\nclassification\n\n\nprecision\n\n\nrecall\n\n\nf1-score\n\n\ncode\n\n\nPCA analysis\n\n\nConfusion Matrix\n\n\nRandomizedSearch\n\n\nvisualization\n\n\nMulti-Class\n\n\n\n\n\n\n\n\n\n\n\nNov 18, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nMulticlass Classification on Fashion MNIST Dataset\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nAnalyzing distribution of numeric features with histogram plot\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items\n\n\n  \n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sai Sundeep Rayidi",
    "section": "",
    "text": "Hi, I am Sai, a Computer Science graduate student at Virginia Tech. I blog about Data Analytics, Visualization and Machine Learning. When not innovating on these topics, I enjoy reading, prepping for a half-marathon, and playing cricket."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Sai Sundeep Rayidi",
    "section": "Education",
    "text": "Education\nVirginia Tech, Falls Church | D.C. Area, VA MEng in Computer Science and Application | August 2023 - Present\nJawaharlal Nehru Technological University | Hyderabad, India Bachelors in Computer Science and Engineering | August 2015 - May 2019"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Sai Sundeep Rayidi",
    "section": "Experience",
    "text": "Experience\nVerizon AI & DATA | Data Engineer | October 2021 - June 2023 Verizon Global Network & Technology | Systems Engineer | August 2019 - September 2021"
  },
  {
    "objectID": "posts/Anomaly Detection/index.html",
    "href": "posts/Anomaly Detection/index.html",
    "title": "Anomaly Detection",
    "section": "",
    "text": "This is a post with executable code about Anomaly Detection using Machine Learning Algorithms.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Classification/index.html",
    "href": "posts/Classification/index.html",
    "title": "Multiclass Classification on Fashion MNIST Dataset",
    "section": "",
    "text": "In this blog we will be performing multiclass classification on the Fashion MNIST dataset. The dataset contains 60,000 images for training and 10,000 images for validation of 10 different types of fashion products. Multiclass classification is a classification task with more than two classes. Each sample can only be labeled as one class. For example, in the context of fashion-mnist images, each image can be of either a shirt, a sneaker, or a trouser. Each image is one sample and is labeled as one of the 10 possible classes. Multiclass classification makes the assumption that each sample is assigned to one and only one label - one sample cannot, for example, be both a shirt and a coat.\nWe will be performing the following tasks in this blog - * Import, analyze, and visualize the fashion-mnist dataset. * Prepare the data for classification + Principal Component Analysis + Hyperparameter Tuning with Randomized Search * Train a RandomForestClassifier and visualize its performance metrics * Observations and Conclusion\nLet us begin by importing a few packages and loading the data into a pandas dataframe.\n\n1. Import, analyze, and visualize the fashion-mnist dataset.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(category=UserWarning, action='ignore')\n\n\n# Load the train and test datasets\nfmnist_train_df = pd.read_csv(\"fashion_mnist_train.csv\")\nfmnist_test_df = pd.read_csv(\"fashion_mnist_test.csv\")\n\n\nprint(f'Train Set Dimensions - {fmnist_train_df.shape}')\nprint(f'Test Set Dimensions - {fmnist_test_df.shape}')\n\nTrain Set Dimensions - (60000, 785)\nTest Set Dimensions - (10000, 785)\n\n\nLet us print a few records from the training set and see how the data looks like.\n\nfmnist_train_df.head(10)\n\n\n\n\n\n\n\n\nlabel\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\npixel9\n...\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\npixel784\n\n\n\n\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n9\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n6\n0\n0\n0\n0\n0\n0\n0\n5\n0\n...\n0\n0\n0\n30\n43\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n1\n2\n0\n0\n0\n0\n...\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n4\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n5\n4\n0\n0\n0\n5\n4\n5\n5\n3\n5\n...\n7\n8\n7\n4\n3\n7\n5\n0\n0\n0\n\n\n6\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n14\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n7\n5\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n8\n4\n0\n0\n0\n0\n0\n0\n3\n2\n0\n...\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n9\n8\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n203\n214\n166\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n10 rows × 785 columns\n\n\n\nWe can see that most of the data is 0 with few values here and there. That is because each row is a 28 * 28 pixel image flattened into an [784,] array. Each element con contain a value between 0 and 255. Furthermore, the target feature named as label is having values from 0 to 9. We will have to process this column a little bit, to make more sense in the context of fashion products that we need to predict. We will see how to do that in just a bit, but first, let us try to reshape the images into 28 * 28 and try to visualize them using the matplotlib subplots.\n\n# Visualize the Images in the Dataset\nlabels_list = list(fmnist_train_df['label'].unique())\nlabels_list.sort()\nfig, axs = plt.subplots(10, 10, figsize=(12, 12), layout='constrained')\nfor i in range(0, 10):\n    class_df = fmnist_train_df[fmnist_train_df['label'] == labels_list[i]]\n    for j in range(0, 10):\n        sample_image = class_df.iloc[j, 1:].values.reshape(28, 28)\n        axs[i][j].imshow(sample_image, cmap='Blues')\n        axs[i][j].grid(False)\n        if j == 0: axs[i][j].set_ylabel(f\"Class {labels_list[i]}\")\nplt.grid(False)\nplt.show()\n\n\n\n\nWe can see from the above plot different kinds of fashion products in the dataset. An obvious difficulty our multiclass classification algorith may face is the close resemblance of three different classes - class 0, class 2, and class 6. Fashion MNIST labels these classes as T-shirt/Top, Pullover, and Shirt respectively. To make target classes clear for us going forward, let us write a helper function that maps, the respective class number to its corresponding label.\n\n# Create more descriptive labels\ndef label_mapper(input):\n    match input:\n        case 0:\n            return 'T-shirt/top'\n        case 1:\n            return 'Trouser'\n        case 2:\n            return 'Pullover'\n        case 3:\n            return 'Dress'\n        case 4:\n            return 'Coat'\n        case 5:\n            return 'Sandal'\n        case 6:\n            return 'Shirt'\n        case 7:\n            return 'Sneaker'\n        case 8:\n            return 'Bag'\n        case 9:\n            return 'Ankle boot'\n\nfmnist_train_df['label'] = fmnist_train_df['label'].apply(lambda x:label_mapper(x))\nfmnist_test_df['label'] = fmnist_test_df['label'].apply(lambda x:label_mapper(x))\n\nLet us visualize if these changes took effect in the label column by printing a few values.\n\nfmnist_train_df['label'].head(10)\n\n0       Pullover\n1     Ankle boot\n2          Shirt\n3    T-shirt/top\n4          Dress\n5           Coat\n6           Coat\n7         Sandal\n8           Coat\n9            Bag\nName: label, dtype: object\n\n\n\n\n2. Prepare the data for classification\n\n# Split the data into predictors (features) and target (label) in train and test sets\nX_train = fmnist_train_df.iloc[:, 1:]\nX_test = fmnist_test_df.iloc[:, 1:]\ny_train = fmnist_train_df['label'].values\ny_test = fmnist_test_df['label'].values\n\nWe already have the training and test set split for us. So let us just separate the predictor and target variables into matrix X (actually pandas DataFrame) and vector y (a pandas series) from training and test set. We will beusing the X_train and y_train to fit a classification model. We will then be using y_test to make prediction on samples that are unseen by the trained multiclass classification model. Finally, we will use y_test to evaluate our model.\nBefore we get ahead to the model, we will need to do some preprocessing. Image classification is a computationally expensive task and training 60,000 images each of 28*28 pixels can take significant of computing resources and training time. Furthermore, we do not have to invest as much resources, because very often only a portion of the images are useful for training. Take for example, in the below image of a pullover, a RandomForestClassifier trained on training data of 1000 samples, showing the important pixels in the image.\n\nfrom sklearn.ensemble import RandomForestClassifier\nrnd_clf = RandomForestClassifier(n_estimators=100)\nrnd_clf.fit(X_train[:1000], y_train[:1000])\n\nheatmap_image = rnd_clf.feature_importances_.reshape(28, 28)\nplt.imshow(heatmap_image, cmap=\"hot\")\ncbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(),\n                           rnd_clf.feature_importances_.max()])\ncbar.ax.set_yticklabels(['Not important', 'Very important'], fontsize=14)\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n2.1 Principal Component Analysis\nAn amazingly helpful strategy to reduce the number of features in the dataset is Principal Component Analysis (PCA). PCA is a dimensionality reduction technique, that transforms the original feature space into a reduced feature space of orthogonal components such that the transformed feature space retains as much variance as possible from the original space. This transformed coordinate system for the principal components. The first principal component can equivalently be defined as a direction that maximizes the variance of the projected data. The i-th principal component can be taken as a direction orthogonal to the first i-1 principal components that maximizes the variance of the projected data.\nIt can be shown that the principal components are eigenvectors of the data’s covariance matrix. Thus, the principal components are often computed by eigendecomposition of the data covariance matrix or singular value decomposition (SVD) of the data matrix. In SVD, we will start from the original data matrix X which has samples in rows and measured variables in columns. The SVD decomposition breaks this matrix X into three matrices -\n\\[ X(n × p) = U_(n × p) * D_(p × p) * V^T_(p × p) \\]\nWhere, - X contains the original data - The columns of U are vectors giving the principal axes. These define the new coordinate system. - The scores can be obtained by XV; scores are the projections of the data on the principal axes. - D is a diagonal matrix, which means all non-diagonal elements are zero. The diagonal contains positive values sorted from largest to smallest. These are called the singular values. - The columns of V are the PCA loadings\nIn addition, U and V are semi-orthogonal matrices, which means that when pre-multiplied by their transpose one gets the identity matrix:\n\\[ U^T * U = I \\] \\[ V^T * V = I \\]\nTo reduce the number of features from 784, We will perform PCA on the fashion-mnist dataset. Before we do that we need to scale our data. PCA assumes that data is normally distributed and is sensitive to the variance of variables, so we scale the data to ensure all variables are on the same scale. This also improves the performance of the algorithm and its prediction accuracy.\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\npca = PCA()\npca.fit(X_train)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nncomponents_95_variance = np.argmax(cumulative_variance &gt;= 0.95) + 1\nprint(f\"Number of Components needed for 95% Variance - {ncomponents_95_variance}\")\n\nNumber of Components needed for 95% Variance - 256\n\n\nTo above step, creates an instance of StandardScaler and fits and transforms the trianing images. The test images are then scaled. The next part performs a full PCA analysis on the training set and calculates the cumulative explained variance - this is the sum of variance by individual principal components. As we can see, to retain 95% of the variance in the dataset, we need just 256 features. It is now computationally manageable for us to train the classifier using a subset of features. One drawback of PCA however is that, it does not tell us which features to retain and which to drop. That is why we will rely on a powerful classifier like RandomForestClassifier, which supports feature sampling.\nBefore that, let me show you a very useful plot that will allow you to visualize the number of components versus the explained variance. This plot allows you to see, how many components you need to retain certain amount of variance in the reduced feature space. For example, in the below plot you can see that, we need only 150 features to explain 91% of the variance in the data. We can build a pretty good model with that variance and strong classifier.\n\nplt.figure(figsize=(8, 6))\nplt.plot(np.arange(1, len(pca.explained_variance_ratio_)+1, 1), np.cumsum(pca.explained_variance_ratio_)*100)\nplt.plot([150, 150], [0, 91], \"k:\")\nplt.plot([0, 150], [91, 91], \"r:\")\nplt.plot(150, 91, \"ro\")\nplt.text(x=-20, y=91, s='91%', color='red', weight='bold', ha='center', va='center')\nplt.text(x=150, y=-3.5, s='150', color='blue', weight='bold', ha='center', va='center')\nplt.axis([0, 600, 0, 100])\nplt.title(\"Fashion MNIST PCA Analysis - Explained Variance vs # of Components\")\nplt.xlabel(\"Number of Components\", weight='bold')\nplt.ylabel(\"Explained Cumulative Variance (%)\", weight='bold')\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.grid(which='major', linestyle='-')\nplt.show()\n\n\n\n\n\n\n2.2 Hyperparameter Tuning with Randomized Search\nWe can also use hyperparameter tuning to search for best parameters. This is called Hyperparameter Optimization or Hyperparameter Tuning. Scikit learn’s GridSearchCV or RandomizedSearchCV can help with hyperparameter tuning. We can get the best values for number of components from principal component analysis and number of estimators from RandomForestClassifier using these methods. RandomizedSearchCV is preferred over GridSearchCV when there are many parameter values to try out. In contrast to GridSearchCV, RandomizedSearchCV tries not all parameter values but rather a fixed number of parameter settings sampled from the specified distributions making the search for best parameters quicker.\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\n\npreprocess_pipeline = make_pipeline(PCA(random_state=5805), RandomForestClassifier(random_state=5805))\nparams_distribution = {\n    \"pca__n_components\": np.arange(50, 250), \n    \"randomforestclassifier__n_estimators\": np.arange(100, 400)\n}\nrandomized_search = RandomizedSearchCV(preprocess_pipeline, params_distribution, n_iter=10, cv=3, random_state=5805)\nrandomized_search.fit(X_train[:1000], y_train[:1000])\n\nRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('pca', PCA(random_state=5805)),\n                                             ('randomforestclassifier',\n                                              RandomForestClassifier(random_state=5805))]),\n                   param_distributions={'pca__n_components': array([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n        63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n        76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,...\n       308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n       321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n       334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n       347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359,\n       360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n       373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n       386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n       399])},\n                   random_state=5805)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('pca', PCA(random_state=5805)),\n                                             ('randomforestclassifier',\n                                              RandomForestClassifier(random_state=5805))]),\n                   param_distributions={'pca__n_components': array([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n        63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n        76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,...\n       308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n       321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n       334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n       347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359,\n       360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n       373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n       386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n       399])},\n                   random_state=5805)estimator: PipelinePipeline(steps=[('pca', PCA(random_state=5805)),\n                ('randomforestclassifier',\n                 RandomForestClassifier(random_state=5805))])PCAPCA(random_state=5805)RandomForestClassifierRandomForestClassifier(random_state=5805)\n\n\nWe can then use the best_params_ attribute from the model to see the parameters that give best results. Note that above I have performed the search on 1000 training instances. Fell free to try and train on more instances. As you can see below, the number of estimators (desision tree classifiers) required by RandomForestClassifier are 197 and number of features are 234.\n\nrandomized_search.best_params_\n\n{'randomforestclassifier__n_estimators': 197, 'pca__n_components': 234}\n\n\n\n\n3. Train a RandomForestClassifier and visualize its performance metrics\nUsing this analysis and hyperparameters, let us now proceed to train the classifier. We will use the n_estimators in RandomForestClassifier to be 197 and fit method to train the classifier. We will use the predict method of the classifier to get the predictions the classifier will make on the dataset. Let us store them in y_pred which we can later use for evaluating the classifier.\n\n# Perform PCA Transform with above n_components\npca = PCA(n_components=234, random_state=5805)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\n\n\n# Train classifier\nrandom_forest_classifier = RandomForestClassifier(n_estimators=197, random_state=5805)\nrandom_forest_classifier.fit(X_train, y_train)\ny_pred = random_forest_classifier.predict(X_test)\n\nNow that we have trained our model and obtained the predictions from it for the test set. It is time to evaluate its performance. A very useful tool for evaluating the multiclass classification model is the classification_report from the sklearn metrics module. It gives us the precision, recall, and f1-score for each class. It also gives the overall f1-score of the classifier and a few other metrics we will discuss in just a second. We can extract the classification_report as follows -\n\nfrom sklearn.metrics import classification_report\n\nprint(\n    f\"Classification report for {random_forest_classifier}:\\n\"\n    f\"{classification_report(y_test, y_pred)}\\n\"\n)\n\nClassification report for RandomForestClassifier(n_estimators=197, random_state=5805):\n              precision    recall  f1-score   support\n\n  Ankle boot       0.89      0.94      0.92      1000\n         Bag       0.93      0.97      0.95      1000\n        Coat       0.79      0.87      0.83      1000\n       Dress       0.88      0.92      0.90      1000\n    Pullover       0.80      0.79      0.80      1000\n      Sandal       0.93      0.90      0.92      1000\n       Shirt       0.74      0.57      0.65      1000\n     Sneaker       0.90      0.88      0.89      1000\n T-shirt/top       0.79      0.84      0.82      1000\n     Trouser       0.99      0.96      0.98      1000\n\n    accuracy                           0.87     10000\n   macro avg       0.86      0.87      0.86     10000\nweighted avg       0.86      0.87      0.86     10000\n\n\n\n\nSo how do we read this classification report? Let us first define each of the metrics.\n\nPrecision - In a multi-class classification task, the precision for a class is the number of true positives (i.e. the number of images correctly labelled as belonging to the positive class) divided by the total number of elements labelled as belonging to the positive class (i.e. the sum of true positives and false positives, which are images incorrectly labelled as belonging to the class).\n\n\\[ {\\displaystyle \\mathrm {PPV} ={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FP} }}=1-\\mathrm {FDR} } \\]\n\nRecall - Recall in this context is defined as the number of true positives divided by the total number of images that actually belong to the positive class (i.e. the sum of true positives and false negatives, which are images which were not labelled as belonging to the positive class but should have been).\n\n\\[ {\\displaystyle \\mathrm {TPR} ={\\frac {\\mathrm {TP} }{\\mathrm {P} }}={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }}=1-\\mathrm {FNR} } \\]\n\nPrecision and recall are not particularly useful metrics when used in isolation. The need to be used in conjunction with other metrics to obtain a comprehensive evaluation of the model’s performance. For instance, A trivial way to have perfect precision is to create a classifier that always makes negative predictions, except for one single positive prediction on the instance it’s most confident about. If this one prediction is correct, then the classifier has 100% precision. Such a classifer would not be any helpful. Likewise, it is possible to have perfect recall by simply retrieving every single item. - F1-score and Accuracy - The F1-score is a metric that combines precision and recall to obtain a balanced classification model. The F1 score favors classifiers that have similar precision and recall. It is calculated as the harmonic mean of precision and recall. Accuracy is another metric that measures the proportion of correct predictions made by the model.\n\nF1 Score \\[ {\\displaystyle \\mathrm {F} _{1}=2\\times {\\frac {\\mathrm {PPV} \\times \\mathrm {TPR} }{\\mathrm {PPV} +\\mathrm {TPR} }}={\\frac {2\\mathrm {TP} }{2\\mathrm {TP} +\\mathrm {FP} +\\mathrm {FN} }}} \\]\nAccuracy (ACC) \\[ {\\displaystyle \\mathrm {ACC} ={\\frac {\\mathrm {TP} +\\mathrm {TN} }{\\mathrm {P} +\\mathrm {N} }}={\\frac {\\mathrm {TP} +\\mathrm {TN} }{\\mathrm {TP} +\\mathrm {TN} +\\mathrm {FP} +\\mathrm {FN} }}} \\]\nAnathor important tool to evaluate the classifier is the Confusion Matrix, in the multi-class classification context, it gives the actual predictions in horizontal rows and predicted classes in vertical columns. We can use the ConfusionMatrixDisplay from scikit learn’s metrics module to plot the confusion matrix for the classifier.\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\ndisp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\ndisp.figure_.suptitle(\"Confusion Matrix\")\nprint(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\nplt.grid(False)\nplt.xticks(rotation=60)\nplt.show()\n\nConfusion matrix:\n[[944   0   0   0   0  20   0  36   0   0]\n [  0 975   4   4   4   2   7   2   2   0]\n [  0   8 868  24  51   0  49   0   0   0]\n [  0   3  24 922   8   0  14   0  24   5]\n [  0  13 117  10 788   1  57   0  14   0]\n [ 36   6   0   0   0 902   0  56   0   0]\n [  0  25  82  23 113   0 575   0 182   0]\n [ 76   1   0   0   0  41   0 882   0   0]\n [  1  20   4  40  13   5  71   1 844   1]\n [  1   1   3  20   4   0   4   0   3 964]]\n\n\n\n\n\nWe can normalize the confusion matrix by dividing each value by the total number of images in the corresponding (true) class (i.e., divide by the row’s sum). This helps us to see where the model has misclassfied the images of a given class as belonging to different class.\n\n# Plot the normalized confused matrix.\nConfusionMatrixDisplay.from_predictions(y_test, y_pred, normalize='true', values_format=\".0%\")\nplt.grid()\nplt.title(\"Normalized Confusion Matrix\")\nplt.xticks(rotation=60)\nplt.show()\n\n\n\n\n\n\n4. Observations and Conclusion\nLooking at the classification report, ROC Curve, and confusion matrix, we can make following observations -\nThe precision for “coat”, “shirt”, “pullover”, and “T-shirt/top” is very low. This tells us that the model is predicting many False Positives for these classes. This is because these four classes are closely resembling one another. The classifier is unable to tell apart confidently a “coat” from a “shirt” and is resulting in many false positives and low precision. One way to improve the model precision for these labels is to increase the number of samples so that model can learn the subtle differences to tell apart each of these classes.\nThe recall for shirt is very low 57%. This tells that many images of shirt have been misclassified as belonging to a different class. Looking at the normalized confusin matrix, we can see that 18% of shirts have been misclassified as T-Shirt/Top, 11% of the shirts have been misclassified as pullover and 8% as Coats. We can see the same issue with images of pullover and coat, they have been misclassified as these other similar looking products.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Probability Theory and Random Variables/index.html",
    "href": "posts/Probability Theory and Random Variables/index.html",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "This is a post with executable code.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Regression/index.html",
    "href": "posts/Regression/index.html",
    "title": "Linear and Non-Linear Regression",
    "section": "",
    "text": "This is a post on regression analysis on diamonds dataset.\n\n\nCode\n#Import Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nsns.set_theme(style=\"darkgrid\")\n\n\n\n\nCode\ndiamonds = sns.load_dataset('diamonds')\nprint(diamonds.shape)\nprint(diamonds.describe())\nprint(diamonds.head(10))\n\n\n(53940, 10)\n              carat         depth         table         price             x  \\\ncount  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \nmean       0.797940     61.749405     57.457184   3932.799722      5.731157   \nstd        0.474011      1.432621      2.234491   3989.439738      1.121761   \nmin        0.200000     43.000000     43.000000    326.000000      0.000000   \n25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \nmax        5.010000     79.000000     95.000000  18823.000000     10.740000   \n\n                  y             z  \ncount  53940.000000  53940.000000  \nmean       5.734526      3.538734  \nstd        1.142135      0.705699  \nmin        0.000000      0.000000  \n25%        4.720000      2.910000  \n50%        5.710000      3.530000  \n75%        6.540000      4.040000  \nmax       58.900000     31.800000  \n   carat        cut color clarity  depth  table  price     x     y     z\n0   0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n1   0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n2   0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n3   0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n4   0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n5   0.24  Very Good     J    VVS2   62.8   57.0    336  3.94  3.96  2.48\n6   0.24  Very Good     I    VVS1   62.3   57.0    336  3.95  3.98  2.47\n7   0.26  Very Good     H     SI1   61.9   55.0    337  4.07  4.11  2.53\n8   0.22       Fair     E     VS2   65.1   61.0    337  3.87  3.78  2.49\n9   0.23  Very Good     H     VS1   59.4   61.0    338  4.00  4.05  2.39\n\n\n\n\nCode\nsns.histplot(data=diamonds, x='price', kde=True)\nplt.title('Diamonds Dataset - Price Distribution')\nplt.ylabel(\"# of sales\")\nplt.xlabel(\"Price\")\nplt.grid('both')\nplt.show()\n\n\n\n\n\n\n\nCode\nsns.countplot(data=diamonds, y='cut', order=diamonds['cut'].value_counts().index,\n              palette=sns.color_palette('flare', 10))\nplt.title('Diamonds Dataset - sales by cut type')\nplt.xlabel('# of Sales')\nplt.ylabel('Cut Type')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\nsns.countplot(data=diamonds, y='clarity', \n              order = diamonds['clarity'].value_counts(ascending=True).index,\n              palette=sns.color_palette('flare', 10))\nplt.xlabel('# of Sales')\nplt.ylabel('Clarity Type')\nplt.title('Diamonds Dataset - Sales by Clarity Type')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\nsns.countplot(data=diamonds, \n              x = 'color', \n              order = diamonds['color'].value_counts(ascending=False).index,\n              palette=sns.color_palette('flare', 10))\nplt.ylabel('# of Sales')\nplt.xlabel('Color')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\nsns.kdeplot(diamonds, x='price', hue='color', common_norm=False)\nplt.show()\n\n\n\n\n\n\n\nCode\ndiamonds['clarity'].value_counts(ascending=False)\n\n\nclarity\nSI1     13065\nVS2     12258\nSI2      9194\nVS1      8171\nVVS2     5066\nVVS1     3655\nIF       1790\nI1        741\nName: count, dtype: int64\n\n\n\n\nCode\ndiamonds['color'].value_counts(ascending=False)\n\n\ncolor\nG    11292\nE     9797\nF     9542\nH     8304\nD     6775\nI     5422\nJ     2808\nName: count, dtype: int64\n\n\n\n\nCode\ndiamonds['cut'].value_counts(ascending=False)\n\n\ncut\nIdeal        21551\nPremium      13791\nVery Good    12082\nGood          4906\nFair          1610\nName: count, dtype: int64\n\n\n\n\nCode\n# Analyzing distribution of numeric features with histogram plot\nsns.set_theme(style=\"whitegrid\")\ndiamonds.hist(bins=50, figsize=(12, 8))\nplt.show()\n\n\n\n\n\n\n\nCode\ncorr_matrix = diamonds.select_dtypes(np.number).corr()\n\n\n\n\nCode\ncorr_matrix['price'].sort_values(ascending=False)\n\n\nprice    1.000000\ncarat    0.921591\nx        0.884435\ny        0.865421\nz        0.861249\ntable    0.127134\ndepth   -0.010647\nName: price, dtype: float64\n\n\n\n\nCode\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(diamonds[['price', 'carat', 'x', 'y', 'z', 'table', 'depth']], figsize=(15, 10))\nplt.show()\n\n\n\n\n\n\n\nCode\nfrom prettytable import PrettyTable\ndef pretty_printing_function(correlation_name, row_values, column_names):\n    summary_table = PrettyTable()\n    summary_table.title = f\"{correlation_name} Correlation Matrix for the tute1 dataset\"\n    column_names = [f'Feature({chr(0x2193)})/({chr(0x2192)})'] + column_names\n    summary_table.field_names = column_names\n    for i in range(len(row_values)):\n        row_index = column_names[i+1]\n        row_values[i] = [row_index] + row_values[i]\n        summary_table.add_row(row_values[i])\n    print(summary_table)\n\n\ndef calc_pearson_corr(x, y, N):\n    numerator_sum = 0.0; denomnator1_sum = 0.0; denomnator2_sum = 0.0\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    for i in range(N):\n        x_diff = x[i] - x_mean\n        y_diff = y[i] - y_mean\n        numerator_sum += (x_diff * y_diff)\n        denomnator1_sum += np.power(x_diff, 2)\n        denomnator2_sum += np.power(y_diff, 2)\n    pearson_corrcoef = numerator_sum/(np.sqrt(denomnator1_sum)*np.sqrt(denomnator2_sum))\n    return round(pearson_corrcoef, 2)\n\n\ndef calc_partial_corr(x, y, z):\n    r_xy = calc_pearson_corr(x, y, len(diamonds))\n    r_xz = calc_pearson_corr(x, z, len(diamonds))\n    r_yz = calc_pearson_corr(y, z, len(diamonds))\n    partial_corr = (r_xy - (r_xz*r_yz)) / (np.sqrt(1 - r_xz**2) * np.sqrt(1 - r_yz**2))\n    return round(partial_corr, 2)\n\n\ndiamonds_numeric = diamonds.select_dtypes(np.number)\ndef calc_partial_correlation():\n    summary_df = pd.DataFrame(columns = diamonds_numeric.columns, index = diamonds_numeric.columns)\n    for col1 in diamonds_numeric.columns:\n        for col2 in diamonds_numeric.columns:\n            if col1 == col2:\n                summary_df.loc[col1, col2] = 1.0\n            else:\n                other_columns = list(set(diamonds_numeric.columns) - set([col1, col2]))\n                for col3 in other_columns:\n                    summary_df.loc[col1, col2] = calc_partial_corr(diamonds_numeric[col1], diamonds_numeric[col2], diamonds_numeric[col3])\n    pretty_printing_function(\"Partial\", summary_df.values.tolist(), column_names=list(summary_df.columns))\n    return summary_df\n\ncalc_partial_correlation()\n\n\n+-----------------------------------------------------------------------+\n|            Partial Correlation Matrix for the tute1 dataset           |\n+----------------+-------+-------+-------+-------+-------+-------+------+\n| Feature(↓)/(→) | carat | depth | table | price |   x   |   y   |  z   |\n+----------------+-------+-------+-------+-------+-------+-------+------+\n|     carat      |  1.0  | -0.18 |  0.12 |  0.65 |  0.77 |  0.49 | 0.79 |\n|     depth      | -0.18 |  1.0  | -0.32 | -0.17 | -0.48 | -0.37 | 0.19 |\n|     table      |  0.12 | -0.32 |  1.0  |  0.0  |  0.23 |  0.12 | 0.08 |\n|     price      |  0.65 | -0.17 |  0.0  |  1.0  |  0.37 |  0.33 | 0.86 |\n|       x        |  0.77 | -0.48 |  0.23 |  0.37 |  1.0  |  0.64 | 0.88 |\n|       y        |  0.49 | -0.37 |  0.12 |  0.33 |  0.64 |  1.0  | 0.8  |\n|       z        |  0.79 |  0.19 |  0.08 |  0.86 |  0.88 |  0.8  | 1.0  |\n+----------------+-------+-------+-------+-------+-------+-------+------+\n\n\n\n\n\n\n\n\n\ncarat\ndepth\ntable\nprice\nx\ny\nz\n\n\n\n\ncarat\n1.0\n-0.18\n0.12\n0.65\n0.77\n0.49\n0.79\n\n\ndepth\n-0.18\n1.0\n-0.32\n-0.17\n-0.48\n-0.37\n0.19\n\n\ntable\n0.12\n-0.32\n1.0\n0.0\n0.23\n0.12\n0.08\n\n\nprice\n0.65\n-0.17\n0.0\n1.0\n0.37\n0.33\n0.86\n\n\nx\n0.77\n-0.48\n0.23\n0.37\n1.0\n0.64\n0.88\n\n\ny\n0.49\n-0.37\n0.12\n0.33\n0.64\n1.0\n0.8\n\n\nz\n0.79\n0.19\n0.08\n0.86\n0.88\n0.8\n1.0\n\n\n\n\n\n\n\n\n\nCode\ndiamonds.plot(kind=\"scatter\", x=\"price\", y=\"carat\",\n             alpha=0.07, grid=True)\nplt.show()\n\n\n\n\n\n\n\nCode\ndiamonds.shape\ndiamonds.head(10)\n\n\n\n\n\n\n\n\n\ncarat\ncut\ncolor\nclarity\ndepth\ntable\nprice\nx\ny\nz\n\n\n\n\n0\n0.23\nIdeal\nE\nSI2\n61.5\n55.0\n326\n3.95\n3.98\n2.43\n\n\n1\n0.21\nPremium\nE\nSI1\n59.8\n61.0\n326\n3.89\n3.84\n2.31\n\n\n2\n0.23\nGood\nE\nVS1\n56.9\n65.0\n327\n4.05\n4.07\n2.31\n\n\n3\n0.29\nPremium\nI\nVS2\n62.4\n58.0\n334\n4.20\n4.23\n2.63\n\n\n4\n0.31\nGood\nJ\nSI2\n63.3\n58.0\n335\n4.34\n4.35\n2.75\n\n\n5\n0.24\nVery Good\nJ\nVVS2\n62.8\n57.0\n336\n3.94\n3.96\n2.48\n\n\n6\n0.24\nVery Good\nI\nVVS1\n62.3\n57.0\n336\n3.95\n3.98\n2.47\n\n\n7\n0.26\nVery Good\nH\nSI1\n61.9\n55.0\n337\n4.07\n4.11\n2.53\n\n\n8\n0.22\nFair\nE\nVS2\n65.1\n61.0\n337\n3.87\n3.78\n2.49\n\n\n9\n0.23\nVery Good\nH\nVS1\n59.4\n61.0\n338\n4.00\n4.05\n2.39\n\n\n\n\n\n\n\n\n\nCode\n# One-hot encode the categorical variabled before feeding into linear model\nfrom sklearn.preprocessing import OneHotEncoder\n\ndiamonds_cut = diamonds[['cut']]\n\nenc = OneHotEncoder(handle_unknown='ignore')\ndiamonds_cuts_onehot = enc.fit_transform(diamonds_cut)\n\n\n\n\nCode\nenc.categories_\n\n\n[array(['Fair', 'Good', 'Ideal', 'Premium', 'Very Good'], dtype=object)]\n\n\n\n\nCode\nenc.get_feature_names_out()\n\n\narray(['cut_Fair', 'cut_Good', 'cut_Ideal', 'cut_Premium',\n       'cut_Very Good'], dtype=object)\n\n\n\n\nCode\ndiamonds_cuts_onehot.toarray()\n\n\narray([[0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       ...,\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0.]])\n\n\n\n\nCode\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\n\ncategorical_features = ['cut', 'color', 'clarity']\nnumeric_features = ['x', 'y', 'z', 'carat', 'depth', 'table']\n\nnumeric_transformer = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n\npreprocessor = ColumnTransformer(\n    [\n        ('num', numeric_transformer, numeric_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n    ],\n    verbose_feature_names_out=False\n)\n\n\n\n\nCode\ndiamonds_features, diamonds_price = diamonds.loc[:, diamonds.columns != 'price'], diamonds['price']\n\n\n\n\nCode\ndiamonds_features.shape\n\n\n(53940, 9)\n\n\n\n\nCode\ndiamonds_price.shape\n\n\n(53940,)\n\n\n\n\nCode\ndiamonds_features.head()\n\n\n\n\n\n\n\n\n\ncarat\ncut\ncolor\nclarity\ndepth\ntable\nx\ny\nz\n\n\n\n\n0\n0.23\nIdeal\nE\nSI2\n61.5\n55.0\n3.95\n3.98\n2.43\n\n\n1\n0.21\nPremium\nE\nSI1\n59.8\n61.0\n3.89\n3.84\n2.31\n\n\n2\n0.23\nGood\nE\nVS1\n56.9\n65.0\n4.05\n4.07\n2.31\n\n\n3\n0.29\nPremium\nI\nVS2\n62.4\n58.0\n4.20\n4.23\n2.63\n\n\n4\n0.31\nGood\nJ\nSI2\n63.3\n58.0\n4.34\n4.35\n2.75\n\n\n\n\n\n\n\n\n\nCode\nfrom sklearn.model_selection import train_test_split\ndiamonds_features_train, diamonds_features_test, diamonds_price_train, diamonds_price_test = train_test_split(diamonds_features, diamonds_price, test_size=0.25)\n\n#print(diamonds_features_train.head(), diamonds_price_train.head())\n\n\n\n\nCode\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = make_pipeline(preprocessor, LinearRegression())\nlin_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('linearregression', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('linearregression', LinearRegression())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)LinearRegressionLinearRegression()\n\n\n\n\nCode\nlin_reg[:-1].get_feature_names_out()\n\n\narray(['x', 'y', 'z', 'carat', 'depth', 'table', 'cut_Fair', 'cut_Good',\n       'cut_Ideal', 'cut_Premium', 'cut_Very Good', 'color_D', 'color_E',\n       'color_F', 'color_G', 'color_H', 'color_I', 'color_J',\n       'clarity_I1', 'clarity_IF', 'clarity_SI1', 'clarity_SI2',\n       'clarity_VS1', 'clarity_VS2', 'clarity_VVS1', 'clarity_VVS2'],\n      dtype=object)\n\n\n\n\nCode\nlin_reg_input_features = lin_reg[:-1].get_feature_names_out()\npd.Series(lin_reg[-1].coef_.ravel(), index=lin_reg_input_features).plot.bar()\nplt.tight_layout()\n\n\n\n\n\n\n\nCode\ndiamonds_price_predictor = lin_reg.predict(diamonds_features_test)\n\n\n\n\nCode\nlin_reg[-1].coef_\n\n\narray([-1.15234906e+03,  7.85197082e+01, -3.65504992e+01,  5.26242057e+03,\n       -8.91507968e+01, -5.30774984e+01, -1.06221052e+15, -1.06221052e+15,\n       -1.06221052e+15, -1.06221052e+15, -1.06221052e+15, -5.55119485e+14,\n       -5.55119485e+14, -5.55119485e+14, -5.55119485e+14, -5.55119485e+14,\n       -5.55119485e+14, -5.55119485e+14, -3.60092931e+15, -3.60092931e+15,\n       -3.60092931e+15, -3.60092931e+15, -3.60092931e+15, -3.60092931e+15,\n       -3.60092931e+15, -3.60092931e+15])\n\n\n\n\nCode\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, diamonds_price_predictor))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, diamonds_price_predictor))\n\n\nMean Squared Error: 1261730.78\nCoefficient of Determination: 0.92\n\n\n\n\nCode\nfrom sklearn.linear_model import SGDRegressor\n\nsgd_reg = make_pipeline(preprocessor, SGDRegressor(max_iter=1000, tol=1e-5, penalty=None, eta0=0.01, n_iter_no_change=100, random_state=42))\nsgd_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('sgdregressor',\n                 SGDRegressor(n_iter_no_change=100, penalty=None,\n                              random_state=42, tol=1e-05))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('sgdregressor',\n                 SGDRegressor(n_iter_no_change=100, penalty=None,\n                              random_state=42, tol=1e-05))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)SGDRegressorSGDRegressor(n_iter_no_change=100, penalty=None, random_state=42, tol=1e-05)\n\n\n\n\nCode\nprice_predictor_sgd = sgd_reg.predict(diamonds_features_test)\n\n\n\n\nCode\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, price_predictor_sgd))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, price_predictor_sgd))\n\n\nMean Squared Error: 1263241.49\nCoefficient of Determination: 0.92\n\n\n\n\nCode\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr_reg = make_pipeline(preprocessor, RandomForestRegressor())\nrfr_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('randomforestregressor', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)RandomForestRegressorRandomForestRegressor()\n\n\n\n\nCode\nprice_predictor_rfr = rfr_reg.predict(diamonds_features_test)\n\n\n\n\nCode\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, price_predictor_rfr))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, price_predictor_rfr))\n\n\nMean Squared Error: 317507.25\nCoefficient of Determination: 0.98\n\n\n\n\n\n Back to top"
  }
]