{
  "hash": "3f61c0548feb8fee9569f425e0833115",
  "result": {
    "markdown": "---\ntitle: Anomaly Detection and Synthetic Data Generation with Scikit-Learn\nauthor: Sai Sundeep Rayidi\ndate: '2023-12-01'\ncategories:\n  - Anomaly Detection\n  - DBSCAN\n  - Synthetic Data\nimage: anomaly.jpg\n---\n\nUntil now, we have worked with real world datasets and applied several Machine Learning algorithms to them. Sometimes it is also useful to generate synthetic data that closely simulates some real-world examples. In this blogpost, we will see how to generate synthetic data with scikit-learn. Specifically, we will create clusters of data with some anomalies which helps us to learn and apply some Anomaly Detection algorithms. At a high level, we will -\n\n* Generating Synthetic data with scikit-learn\n* Applying DBSCAN to Predict Outliers/Anomalies\n* Gaussian Mixture Models for Anomaly Detection\n\n\n## 1. Generating Synthetic Data with Scikit-learn\n \nScikit-learn has built-in synthetic data generators that can be used for a variety of machine learning tasks. Two such generators are [make_blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs) and [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification) which can create multiclass datasets containing normally distributed clusters of points for each class. In this blog post, we will use the make_blobs generator as it allows greater control over the placement of cluster centers and the standard deviation of points within each cluster. Let us start be creating few clusters using make_blobs.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2023-12-01T13:11:34.782059200Z\",\"start_time\":\"2023-12-01T13:11:34.566244600Z\"}' execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nfrom sklearn.datasets import make_blobs\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\nX, y, centers = make_blobs(n_samples=1500, \n                           centers=4, \n                           n_features=2, \n                           cluster_std=1.8, \n                           random_state=5805, \n                           return_centers=True, \n                           shuffle=True)\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\ncenters_scaled = scaler.transform(centers)\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap='tab10')\nplt.title(\"Four Randomly Generated Gaussian Spherical Blobs with $\\sigma=1.8$\")\nfor i in range(4):\n    plt.scatter(x=centers_scaled[i][0], y=centers_scaled[i][1], s=100, c='black', marker='o')\n    plt.scatter(x=centers_scaled[i][0], y=centers_scaled[i][1], s=100, c='white', marker='x')\nplt.show()\n\nprint(f\"The Centers of the clusters are at: \\n{centers_scaled}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=582 height=432}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe Centers of the clusters are at: \n[[-0.42055743 -1.02171133]\n [ 1.52980404 -0.75580787]\n [-0.80809373  0.3622626 ]\n [-0.29674727  1.43940821]]\n```\n:::\n:::\n\n\nThe above code generated four clusters with the specified standard deviation. Internally make_blobs uses a generative model called the Gaussian Mixture Model(GMM), which is a statistical model that assumes instances (data points) to belong to a finite mixture of Gaussian (normal) distributions with some known parameters. Simply put, GMM is a way of representing dataset as a collection of Gaussian distributions. Each of these distributions represent a cluster of data points, just like the ones shown above. Later in this blog, we will see how to use GMM to detect outliers/anomalies in our data.\n\n### Linear Transformations\n\nAnother useful trick when generating synthetic data is applying linear transformations. Sometimes, we want to make the clusters elliptical rather than circular, or bring the clusters closer to evaluate the performance of the algorithms we want to use. Linear transformations are a great way to do this. Below are the list of transformations and their corresponding matrix forms that are most commonly used -\n\n1. Matrix for **Horizontal shear** \n$$ \\huge A=\\begin{bmatrix}\n    1 &k \\\\\n    0 &1\n\\end{bmatrix} $$\n2. Matrix for **Vertical shear**\n$$ \\huge A=\\begin{bmatrix}\n    1 &0 \\\\\n    k &1\n\\end{bmatrix} $$\n3. Matrix for **Counterclockwise Rotation**\n$$ \\huge A=\\begin{bmatrix}\n    \\cos(\\theta) &-\\sin(\\theta) \\\\\n    \\sin(\\theta) &\\cos(\\theta)\n\\end{bmatrix} $$\n4. Matrix for **reflection** about horizontal axis\n$$ \\huge A=\\begin{bmatrix}\n    1 &0 \\\\\n    0 &-1\n\\end{bmatrix} $$ \n\nLet us apply these transformations on our synthetic data to see how the transformed data look.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2023-12-01T13:11:35.514326500Z\",\"start_time\":\"2023-12-01T13:11:34.785603100Z\"}' execution_count=2}\n``` {.python .cell-code}\nfig = plt.figure(figsize=(10, 10))\nax1 = fig.add_subplot(221)\n\n# Rotation (Clockwise)\nangle45 = 45 * np.pi/180\nangle135 = 135 * np.pi/180\nrotation_transformation = np.array([\n    [np.cos(angle45), np.sin(angle45)], \n    [np.cos(angle135), np.sin(angle135)]\n])\n\nX_rotated = X.dot(rotation_transformation)\nax1.scatter(X_rotated[:, 0], X_rotated[:, 1], c=y, cmap='tab10')\nax1.set_title(\"Clockwise Rotation\")\n\n\n# reflection - Horizontal Axis\nax2 = fig.add_subplot(222)\nreflection_matrix = np.array([\n    [1, 0], \n    [0, -1]\n])\nX_transformed = X.dot(reflection_matrix)\nax2.scatter(X_transformed[:, 0], X_transformed[:, 1], c=y, cmap='tab10')\nax2.set_title(\"Rotation about Horizontal Axis\")\n\n# Horizontal Shearing\nax3 = fig.add_subplot(223)\nhshear_matrix = np.array([\n    [1, 1.5], \n    [0, 1]\n])\nX_hsheared = X.dot(hshear_matrix)\nax3.scatter(X_hsheared[:, 0], X_hsheared[:, 1], c=y, cmap='tab10')\nax3.set_title(\"Horizontal Shearing\")\n\n# Vertical Shearing\nax4 = fig.add_subplot(224)\nvshear_matrix = np.array([\n    [1, 0], \n    [1.5, 1]\n])\nX_vsheared = X.dot(vshear_matrix)\nax4.scatter(X_vsheared[:, 0], X_vsheared[:, 1], c=y, cmap='tab10')\nax4.set_title(\"Vertical Shearing\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=805 height=801}\n:::\n:::\n\n\nYou can pick and choose the transformation according to the type of problem you are simulating or the algorithm you are working with. Now that we have our data ready, let us go on a hunt for the outliers!\n\n## 2. Applying DBSCAN to Predict Outliers/Anomalies\n\nThe Density Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm defines clusters as continuous regions of high density. The algorithm works by defining a neighborhood around each point in the dataset. A neighborhood is defined by two parameters: **$\\epsilon$** (**epsilon**) and **min_samples**. $\\epsilon$ specifies a small distance (radius) around each instance and min_samples denote the minimum number of instances required to be in that instances $\\epsilon$-neighborhood for it to be considered a core instance. All instances in the neighborhood of a core instance belong to the same cluster and any instance that is not a core instance and does not have one in its neighborhood is considered an **Anomaly**.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2023-12-01T13:11:35.578999500Z\",\"start_time\":\"2023-12-01T13:11:35.516391600Z\"}' execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.cluster import DBSCAN\n\ndbscan = DBSCAN(eps=0.2, min_samples=10)\ndbscan.fit(X)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DBSCAN(eps=0.2, min_samples=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DBSCAN</label><div class=\"sk-toggleable__content\"><pre>DBSCAN(eps=0.2, min_samples=10)</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell ExecuteTime='{\"end_time\":\"2023-12-01T13:11:35.761344800Z\",\"start_time\":\"2023-12-01T13:11:35.548444800Z\"}' execution_count=4}\n``` {.python .cell-code}\nlabels = dbscan.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nunique_labels = set(labels)\ncore_samples_mask = np.zeros_like(labels, dtype=bool)\ncore_samples_mask[dbscan.core_sample_indices_] = True\n\ncolors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = [0, 0, 0, 1]\n\n    class_member_mask = labels == k\n\n    xy = X[class_member_mask & core_samples_mask]\n    plt.plot(\n        xy[:, 0],\n        xy[:, 1],\n        \"o\",\n        markerfacecolor=tuple(col),\n        markeredgecolor=\"k\",\n        markersize=14,\n    )\n\n    xy = X[class_member_mask & ~core_samples_mask]\n    plt.plot(\n        xy[:, 0],\n        xy[:, 1],\n        \"o\",\n        markerfacecolor=tuple(col),\n        markeredgecolor=\"k\",\n        markersize=6,\n    )\n\nplt.title(f\"Estimated number of clusters: {n_clusters_}\")\nplt.show()\n\nfrom sklearn.metrics import silhouette_score, homogeneity_score\nprint(f\"silhouette_score: {silhouette_score(X, labels):.2f}\")\nprint(f\"homogeneity_score: {homogeneity_score(y, labels):.2f}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=582 height=431}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nsilhouette_score: 0.54\nhomogeneity_score: 0.70\n```\n:::\n:::\n\n\nLooks like the DBSCAN algorithm could not make out all four clusters in our dataset. But yet it was able to spot many outliers. Let us validate our results with a more precise algorithm like Gaussian Mixture to help cluster the dataset accurately while also predict the outliers. \n\n## 3. Gaussian Mixture Models for Anomaly Detection\n\nWe have seen how to use Gaussian Mixture Models to perform [clustering](https://sai-sundeep.github.io/saisundeep.github.io/posts/Clustering/) tasks when data points are of varying sizes and densities. Another application of GMMs are in Anomaly and Novelty detection. Because they make use of normal distributions and probability densities. We can identify the points with low probability density and label them as anomalies. However, here again choosing the right number of gaussian clusters for the GMM model is essential, incorrectly choosing the number of components can cause the model to either under-fit or over-fit.    \n\n::: {.cell ExecuteTime='{\"end_time\":\"2023-12-01T13:11:35.899623400Z\",\"start_time\":\"2023-12-01T13:11:35.761184500Z\"}' execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.mixture import GaussianMixture\n\ngm = GaussianMixture(n_components=4, n_init=10)\ngm.fit(X)\nprint(f\"cluster centers predicted by Gaussian Mixture Model: \\n {gm.means_}\\n\")\nprint(f\"Actual Centers: \\n {centers_scaled}\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncluster centers predicted by Gaussian Mixture Model: \n [[-0.28867979  1.42304583]\n [-0.82158344  0.35570973]\n [-0.39582404 -1.00586282]\n [ 1.53680021 -0.76325421]]\n\nActual Centers: \n [[-0.42055743 -1.02171133]\n [ 1.52980404 -0.75580787]\n [-0.80809373  0.3622626 ]\n [-0.29674727  1.43940821]]\n```\n:::\n:::\n\n\nAs you can see the centers predicted by the GaussianMixture model is pretty close to the actual centers from or generated data. Also note that unlike DBSCAN, the GaussianMixture was able to correctly predict four clusters in our dataset. Let us label and plot these anomalies.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2023-12-01T13:11:36.152409200Z\",\"start_time\":\"2023-12-01T13:11:35.899623400Z\"}' execution_count=6}\n``` {.python .cell-code}\nimport seaborn as sns\ndensities = gm.score_samples(X)\ndensity_threshold = np.percentile(densities, 2)\ncluster_points = X[densities >= density_threshold]\nanomalies = X[densities < density_threshold]\n\ny_labels = gm.fit_predict(cluster_points)\n\nplt.scatter(cluster_points[:, 0], cluster_points[:, 1], c=y_labels, cmap='tab10')\nplt.scatter(anomalies[:, 0], anomalies[:, 1], c='black', marker='*')\nplt.title(\"Anomalies Detected by GaussianMixture Model\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=582 height=431}\n:::\n:::\n\n\n## Conclusion & Closing Remarks\n\nDBSCAN and Gaussian Mixture Models are powerful unsupervised learning algorithms for clustering and anomaly detection tasks. Each has its own strengths and weaknesses, and choosing the right one depends on the data and problem being tackled. GMMs are particularly good at dealing with complex data distributions, over-lapping and non-spherical clusters. They can also be used for soft clustering to assign multiple probabilities to each point. DBSCAN, on the other hand, is less affected by data noise and can identify clusters with arbitrary shapes. It is, therefore, important to choose the best algorithm that suits the data and problem at hand. \n\nWe also saw how to generate synthetic data using scikit_learn in this blog post. Working with such datasets is both cost-effective and hugely beneficial when specific needs or conditions are not met by the real world data or when privacy concerns limit the data availability. Synthetic datasets are scalable and can help simulate ‘what if’ scenarios, test a hypothesis or model multiple outcomes.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}