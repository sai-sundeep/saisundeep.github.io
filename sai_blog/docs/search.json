[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Regression/diamonds_regression.html",
    "href": "posts/Regression/diamonds_regression.html",
    "title": "Sai's ML blog",
    "section": "",
    "text": "#Import Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nsns.set_theme(style=\"darkgrid\")\n\n\ndiamonds = sns.load_dataset('diamonds')\nprint(diamonds.shape)\nprint(diamonds.describe())\nprint(diamonds.head(10))\n\n(53940, 10)\n              carat         depth         table         price             x  \\\ncount  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \nmean       0.797940     61.749405     57.457184   3932.799722      5.731157   \nstd        0.474011      1.432621      2.234491   3989.439738      1.121761   \nmin        0.200000     43.000000     43.000000    326.000000      0.000000   \n25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \nmax        5.010000     79.000000     95.000000  18823.000000     10.740000   \n\n                  y             z  \ncount  53940.000000  53940.000000  \nmean       5.734526      3.538734  \nstd        1.142135      0.705699  \nmin        0.000000      0.000000  \n25%        4.720000      2.910000  \n50%        5.710000      3.530000  \n75%        6.540000      4.040000  \nmax       58.900000     31.800000  \n   carat        cut color clarity  depth  table  price     x     y     z\n0   0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n1   0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n2   0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n3   0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n4   0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n5   0.24  Very Good     J    VVS2   62.8   57.0    336  3.94  3.96  2.48\n6   0.24  Very Good     I    VVS1   62.3   57.0    336  3.95  3.98  2.47\n7   0.26  Very Good     H     SI1   61.9   55.0    337  4.07  4.11  2.53\n8   0.22       Fair     E     VS2   65.1   61.0    337  3.87  3.78  2.49\n9   0.23  Very Good     H     VS1   59.4   61.0    338  4.00  4.05  2.39\n\n\n\nsns.histplot(data=diamonds, x='price', kde=True)\nplt.title('Diamonds Dataset - Price Distribution')\nplt.ylabel(\"# of sales\")\nplt.xlabel(\"Price\")\nplt.grid('both')\nplt.show()\n\n\n\n\n\nsns.countplot(data=diamonds, y='cut', order=diamonds['cut'].value_counts().index,\n              palette=sns.color_palette('flare', 10))\nplt.title('Diamonds Dataset - sales by cut type')\nplt.xlabel('# of Sales')\nplt.ylabel('Cut Type')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nsns.countplot(data=diamonds, y='clarity', \n              order = diamonds['clarity'].value_counts(ascending=True).index,\n              palette=sns.color_palette('flare', 10))\nplt.xlabel('# of Sales')\nplt.ylabel('Clarity Type')\nplt.title('Diamonds Dataset - Sales by Clarity Type')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nsns.countplot(data=diamonds, \n              x = 'color', \n              order = diamonds['color'].value_counts(ascending=False).index,\n              palette=sns.color_palette('flare', 10))\nplt.ylabel('# of Sales')\nplt.xlabel('Color')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nsns.kdeplot(diamonds, x='price', hue='color', common_norm=False)\nplt.show()\n\n\n\n\n\ndiamonds['clarity'].value_counts(ascending=False)\n\nclarity\nSI1     13065\nVS2     12258\nSI2      9194\nVS1      8171\nVVS2     5066\nVVS1     3655\nIF       1790\nI1        741\nName: count, dtype: int64\n\n\n\ndiamonds['color'].value_counts(ascending=False)\n\ncolor\nG    11292\nE     9797\nF     9542\nH     8304\nD     6775\nI     5422\nJ     2808\nName: count, dtype: int64\n\n\n\ndiamonds['cut'].value_counts(ascending=False)\n\ncut\nIdeal        21551\nPremium      13791\nVery Good    12082\nGood          4906\nFair          1610\nName: count, dtype: int64\n\n\n\n# Analyzing distribution of numeric features with histogram plot\nsns.set_theme(style=\"whitegrid\")\ndiamonds.hist(bins=50, figsize=(12, 8))\nplt.show()\n\n\n\n\n\ncorr_matrix = diamonds.select_dtypes(np.number).corr()\n\n\ncorr_matrix['price'].sort_values(ascending=False)\n\nprice    1.000000\ncarat    0.921591\nx        0.884435\ny        0.865421\nz        0.861249\ntable    0.127134\ndepth   -0.010647\nName: price, dtype: float64\n\n\n\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(diamonds[['price', 'carat', 'x', 'y', 'z', 'table', 'depth']], figsize=(15, 10))\nplt.show()\n\n\n\n\n\nfrom prettytable import PrettyTable\ndef pretty_printing_function(correlation_name, row_values, column_names):\n    summary_table = PrettyTable()\n    summary_table.title = f\"{correlation_name} Correlation Matrix for the tute1 dataset\"\n    column_names = [f'Feature({chr(0x2193)})/({chr(0x2192)})'] + column_names\n    summary_table.field_names = column_names\n    for i in range(len(row_values)):\n        row_index = column_names[i+1]\n        row_values[i] = [row_index] + row_values[i]\n        summary_table.add_row(row_values[i])\n    print(summary_table)\n\n\ndef calc_pearson_corr(x, y, N):\n    numerator_sum = 0.0; denomnator1_sum = 0.0; denomnator2_sum = 0.0\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    for i in range(N):\n        x_diff = x[i] - x_mean\n        y_diff = y[i] - y_mean\n        numerator_sum += (x_diff * y_diff)\n        denomnator1_sum += np.power(x_diff, 2)\n        denomnator2_sum += np.power(y_diff, 2)\n    pearson_corrcoef = numerator_sum/(np.sqrt(denomnator1_sum)*np.sqrt(denomnator2_sum))\n    return round(pearson_corrcoef, 2)\n\n\ndef calc_partial_corr(x, y, z):\n    r_xy = calc_pearson_corr(x, y, len(diamonds))\n    r_xz = calc_pearson_corr(x, z, len(diamonds))\n    r_yz = calc_pearson_corr(y, z, len(diamonds))\n    partial_corr = (r_xy - (r_xz*r_yz)) / (np.sqrt(1 - r_xz**2) * np.sqrt(1 - r_yz**2))\n    return round(partial_corr, 2)\n\n\ndiamonds_numeric = diamonds.select_dtypes(np.number)\ndef calc_partial_correlation():\n    summary_df = pd.DataFrame(columns = diamonds_numeric.columns, index = diamonds_numeric.columns)\n    for col1 in diamonds_numeric.columns:\n        for col2 in diamonds_numeric.columns:\n            if col1 == col2:\n                summary_df.loc[col1, col2] = 1.0\n            else:\n                other_columns = list(set(diamonds_numeric.columns) - set([col1, col2]))\n                for col3 in other_columns:\n                    summary_df.loc[col1, col2] = calc_partial_corr(diamonds_numeric[col1], diamonds_numeric[col2], diamonds_numeric[col3])\n    pretty_printing_function(\"Partial\", summary_df.values.tolist(), column_names=list(summary_df.columns))\n    return summary_df\n\ncalc_partial_correlation()\n\n+---------------------------------------------------------------------+\n|           Partial Correlation Matrix for the tute1 dataset          |\n+----------------+-------+-------+-------+-------+------+------+------+\n| Feature(↓)/(→) | carat | depth | table | price |  x   |  y   |  z   |\n+----------------+-------+-------+-------+-------+------+------+------+\n|     carat      |  1.0  |  0.09 |  0.2  |  0.92 | 0.98 | 0.95 | 0.95 |\n|     depth      |  0.09 |  1.0  | -0.32 |  0.03 | 0.03 | 0.03 | 0.14 |\n|     table      |  0.2  | -0.32 |  1.0  |  0.13 | 0.2  | 0.18 | 0.19 |\n|     price      |  0.92 |  0.03 |  0.13 |  1.0  | 0.88 | 0.87 | 0.86 |\n|       x        |  0.98 |  0.03 |  0.2  |  0.88 | 1.0  | 0.97 | 0.98 |\n|       y        |  0.95 |  0.03 |  0.18 |  0.87 | 0.97 | 1.0  | 0.96 |\n|       z        |  0.95 |  0.14 |  0.19 |  0.86 | 0.98 | 0.96 | 1.0  |\n+----------------+-------+-------+-------+-------+------+------+------+\n\n\n\n\n\n\n\n\n\ncarat\ndepth\ntable\nprice\nx\ny\nz\n\n\n\n\ncarat\n1.0\n0.09\n0.2\n0.92\n0.98\n0.95\n0.95\n\n\ndepth\n0.09\n1.0\n-0.32\n0.03\n0.03\n0.03\n0.14\n\n\ntable\n0.2\n-0.32\n1.0\n0.13\n0.2\n0.18\n0.19\n\n\nprice\n0.92\n0.03\n0.13\n1.0\n0.88\n0.87\n0.86\n\n\nx\n0.98\n0.03\n0.2\n0.88\n1.0\n0.97\n0.98\n\n\ny\n0.95\n0.03\n0.18\n0.87\n0.97\n1.0\n0.96\n\n\nz\n0.95\n0.14\n0.19\n0.86\n0.98\n0.96\n1.0\n\n\n\n\n\n\n\n\ndiamonds.plot(kind=\"scatter\", x=\"price\", y=\"carat\",\n             alpha=0.07, grid=True)\nplt.show()\n\n\n\n\n\ndiamonds.shape\ndiamonds.head(10)\n\n\n\n\n\n\n\n\ncarat\ncut\ncolor\nclarity\ndepth\ntable\nprice\nx\ny\nz\n\n\n\n\n0\n0.23\nIdeal\nE\nSI2\n61.5\n55.0\n326\n3.95\n3.98\n2.43\n\n\n1\n0.21\nPremium\nE\nSI1\n59.8\n61.0\n326\n3.89\n3.84\n2.31\n\n\n2\n0.23\nGood\nE\nVS1\n56.9\n65.0\n327\n4.05\n4.07\n2.31\n\n\n3\n0.29\nPremium\nI\nVS2\n62.4\n58.0\n334\n4.20\n4.23\n2.63\n\n\n4\n0.31\nGood\nJ\nSI2\n63.3\n58.0\n335\n4.34\n4.35\n2.75\n\n\n5\n0.24\nVery Good\nJ\nVVS2\n62.8\n57.0\n336\n3.94\n3.96\n2.48\n\n\n6\n0.24\nVery Good\nI\nVVS1\n62.3\n57.0\n336\n3.95\n3.98\n2.47\n\n\n7\n0.26\nVery Good\nH\nSI1\n61.9\n55.0\n337\n4.07\n4.11\n2.53\n\n\n8\n0.22\nFair\nE\nVS2\n65.1\n61.0\n337\n3.87\n3.78\n2.49\n\n\n9\n0.23\nVery Good\nH\nVS1\n59.4\n61.0\n338\n4.00\n4.05\n2.39\n\n\n\n\n\n\n\n\n# One-hot encode the categorical variabled before feeding into linear model\nfrom sklearn.preprocessing import OneHotEncoder\n\ndiamonds_cut = diamonds[['cut']]\n\nenc = OneHotEncoder(handle_unknown='ignore')\ndiamonds_cuts_onehot = enc.fit_transform(diamonds_cut)\n\n\nenc.categories_\n\n[array(['Fair', 'Good', 'Ideal', 'Premium', 'Very Good'], dtype=object)]\n\n\n\nenc.get_feature_names_out()\n\narray(['cut_Fair', 'cut_Good', 'cut_Ideal', 'cut_Premium',\n       'cut_Very Good'], dtype=object)\n\n\n\ndiamonds_cuts_onehot.toarray()\n\narray([[0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       ...,\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0.]])\n\n\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\n\ncategorical_features = ['cut', 'color', 'clarity']\nnumeric_features = ['x', 'y', 'z', 'carat', 'depth', 'table']\n\nnumeric_transformer = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n\npreprocessor = ColumnTransformer(\n    [\n        ('num', numeric_transformer, numeric_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n    ],\n    verbose_feature_names_out=False\n)\n\n\ndiamonds_features, diamonds_price = diamonds.loc[:, diamonds.columns != 'price'], diamonds['price']\n\n\ndiamonds_features.shape\n\n(53940, 9)\n\n\n\ndiamonds_price.shape\n\n(53940,)\n\n\n\ndiamonds_features.head()\n\n\n\n\n\n\n\n\ncarat\ncut\ncolor\nclarity\ndepth\ntable\nx\ny\nz\n\n\n\n\n0\n0.23\nIdeal\nE\nSI2\n61.5\n55.0\n3.95\n3.98\n2.43\n\n\n1\n0.21\nPremium\nE\nSI1\n59.8\n61.0\n3.89\n3.84\n2.31\n\n\n2\n0.23\nGood\nE\nVS1\n56.9\n65.0\n4.05\n4.07\n2.31\n\n\n3\n0.29\nPremium\nI\nVS2\n62.4\n58.0\n4.20\n4.23\n2.63\n\n\n4\n0.31\nGood\nJ\nSI2\n63.3\n58.0\n4.34\n4.35\n2.75\n\n\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\ndiamonds_features_train, diamonds_features_test, diamonds_price_train, diamonds_price_test = train_test_split(diamonds_features, diamonds_price, test_size=0.25)\n\n#print(diamonds_features_train.head(), diamonds_price_train.head())\n\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = make_pipeline(preprocessor, LinearRegression())\nlin_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('linearregression', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('linearregression', LinearRegression())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)LinearRegressionLinearRegression()\n\n\n\nlin_reg[:-1].get_feature_names_out()\n\narray(['x', 'y', 'z', 'carat', 'depth', 'table', 'cut_Fair', 'cut_Good',\n       'cut_Ideal', 'cut_Premium', 'cut_Very Good', 'color_D', 'color_E',\n       'color_F', 'color_G', 'color_H', 'color_I', 'color_J',\n       'clarity_I1', 'clarity_IF', 'clarity_SI1', 'clarity_SI2',\n       'clarity_VS1', 'clarity_VS2', 'clarity_VVS1', 'clarity_VVS2'],\n      dtype=object)\n\n\n\nlin_reg_input_features = lin_reg[:-1].get_feature_names_out()\npd.Series(lin_reg[-1].coef_.ravel(), index=lin_reg_input_features).plot.bar()\nplt.tight_layout()\n\n\n\n\n\ndiamonds_price_predictor = lin_reg.predict(diamonds_features_test)\n\n\nlin_reg[-1].coef_\n\narray([-1.18206223e+03, -2.37825898e+00, -3.92994580e+01,  5.39684709e+03,\n       -8.97161459e+01, -5.77167234e+01,  1.98788030e+15,  1.98788030e+15,\n        1.98788030e+15,  1.98788030e+15,  1.98788030e+15,  2.52457342e+15,\n        2.52457342e+15,  2.52457342e+15,  2.52457342e+15,  2.52457342e+15,\n        2.52457342e+15,  2.52457342e+15,  2.20058043e+15,  2.20058043e+15,\n        2.20058043e+15,  2.20058043e+15,  2.20058043e+15,  2.20058043e+15,\n        2.20058043e+15,  2.20058043e+15])\n\n\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, diamonds_price_predictor))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, diamonds_price_predictor))\n\nMean Squared Error: 1318797.39\nCoefficient of Determination: 0.92\n\n\n\nfrom sklearn.linear_model import SGDRegressor\n\nsgd_reg = make_pipeline(preprocessor, SGDRegressor(max_iter=1000, tol=1e-5, penalty=None, eta0=0.01, n_iter_no_change=100, random_state=42))\nsgd_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('sgdregressor',\n                 SGDRegressor(n_iter_no_change=100, penalty=None,\n                              random_state=42, tol=1e-05))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('sgdregressor',\n                 SGDRegressor(n_iter_no_change=100, penalty=None,\n                              random_state=42, tol=1e-05))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)SGDRegressorSGDRegressor(n_iter_no_change=100, penalty=None, random_state=42, tol=1e-05)\n\n\n\nprice_predictor_sgd = sgd_reg.predict(diamonds_features_test)\n\n\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, price_predictor_sgd))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, price_predictor_sgd))\n\nMean Squared Error: 1319437.35\nCoefficient of Determination: 0.92\n\n\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr_reg = make_pipeline(preprocessor, RandomForestRegressor())\nrfr_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('randomforestregressor', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)RandomForestRegressorRandomForestRegressor()\n\n\n\nprice_predictor_rfr = rfr_reg.predict(diamonds_features_test)\n\n\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, price_predictor_rfr))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, price_predictor_rfr))\n\nMean Squared Error: 319594.77\nCoefficient of Determination: 0.98\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Clustering/index.html",
    "href": "posts/Clustering/index.html",
    "title": "Clustering",
    "section": "",
    "text": "This is a post with executable code.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Anomaly Detection/index.html",
    "href": "posts/Anomaly Detection/index.html",
    "title": "Anomaly Detection",
    "section": "",
    "text": "This is a post with executable code about Anomaly Detection using Machine Learning Algorithms.\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sai Sundeep Rayidi",
    "section": "",
    "text": "Hi, I am Sai, a Computer Science graduate student at Virginia Tech. I blog about Data Analytics, Visualization and Machine Learning. When not innovating on these topics, I enjoy reading, prepping for a half-marathon, and playing cricket."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Sai Sundeep Rayidi",
    "section": "Education",
    "text": "Education\nVirginia Tech, Falls Church | D.C. Area, VA MEng in Computer Science and Application | August 2023 - Present\nJawaharlal Nehru Technological University | Hyderabad, India Bachelors in Computer Science and Engineering | August 2015 - May 2019"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Sai Sundeep Rayidi",
    "section": "Experience",
    "text": "Experience\nVerizon AI & DATA | Data Engineer | October 2021 - June 2023 Verizon Global Network & Technology | Systems Engineer | August 2019 - September 2021"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Series",
    "section": "",
    "text": "Welcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2023\n\n\nSai Sundee Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nProbability Theory and Random Variables\n\n\n\n\n\n\n\nprobability theory\n\n\ncode\n\n\nanalysis\n\n\nrandom variables\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nClustering\n\n\n\n\n\n\n\nclustering\n\n\ncode\n\n\nscatter plot\n\n\nanalysis\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nClassification\n\n\n\n\n\n\n\nclassification\n\n\nROC\n\n\nprecision and recall\n\n\ncode\n\n\nanalysis\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nLinear and Non-Linear Regression\n\n\n\n\n\n\n\nregression\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\npolynomial regression\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nAnomaly Detection\n\n\n\n\n\n\n\nanomaly detection\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2023\n\n\nSai Sundeep Rayidi\n\n\n\n\n\n\n  \n\n\n\n\nAnalyzing distribution of numeric features with histogram plot\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items\n\n\n  \n\n Back to top"
  },
  {
    "objectID": "posts/Classification/index.html",
    "href": "posts/Classification/index.html",
    "title": "Classification",
    "section": "",
    "text": "This is a post with executable code.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Probability Theory and Random Variables/index.html",
    "href": "posts/Probability Theory and Random Variables/index.html",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "This is a post with executable code.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/Regression/index.html",
    "href": "posts/Regression/index.html",
    "title": "Linear and Non-Linear Regression",
    "section": "",
    "text": "This is a post on regression analysis on diamonds dataset.\n\n\nCode\n#Import Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nsns.set_theme(style=\"darkgrid\")\n\n\n\n\nCode\ndiamonds = sns.load_dataset('diamonds')\nprint(diamonds.shape)\nprint(diamonds.describe())\nprint(diamonds.head(10))\n\n\n(53940, 10)\n              carat         depth         table         price             x  \\\ncount  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \nmean       0.797940     61.749405     57.457184   3932.799722      5.731157   \nstd        0.474011      1.432621      2.234491   3989.439738      1.121761   \nmin        0.200000     43.000000     43.000000    326.000000      0.000000   \n25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \nmax        5.010000     79.000000     95.000000  18823.000000     10.740000   \n\n                  y             z  \ncount  53940.000000  53940.000000  \nmean       5.734526      3.538734  \nstd        1.142135      0.705699  \nmin        0.000000      0.000000  \n25%        4.720000      2.910000  \n50%        5.710000      3.530000  \n75%        6.540000      4.040000  \nmax       58.900000     31.800000  \n   carat        cut color clarity  depth  table  price     x     y     z\n0   0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n1   0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n2   0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n3   0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n4   0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n5   0.24  Very Good     J    VVS2   62.8   57.0    336  3.94  3.96  2.48\n6   0.24  Very Good     I    VVS1   62.3   57.0    336  3.95  3.98  2.47\n7   0.26  Very Good     H     SI1   61.9   55.0    337  4.07  4.11  2.53\n8   0.22       Fair     E     VS2   65.1   61.0    337  3.87  3.78  2.49\n9   0.23  Very Good     H     VS1   59.4   61.0    338  4.00  4.05  2.39\n\n\n\n\nCode\nsns.histplot(data=diamonds, x='price', kde=True)\nplt.title('Diamonds Dataset - Price Distribution')\nplt.ylabel(\"# of sales\")\nplt.xlabel(\"Price\")\nplt.grid('both')\nplt.show()\n\n\n\n\n\n\n\nCode\nsns.countplot(data=diamonds, y='cut', order=diamonds['cut'].value_counts().index,\n              palette=sns.color_palette('flare', 10))\nplt.title('Diamonds Dataset - sales by cut type')\nplt.xlabel('# of Sales')\nplt.ylabel('Cut Type')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\nsns.countplot(data=diamonds, y='clarity', \n              order = diamonds['clarity'].value_counts(ascending=True).index,\n              palette=sns.color_palette('flare', 10))\nplt.xlabel('# of Sales')\nplt.ylabel('Clarity Type')\nplt.title('Diamonds Dataset - Sales by Clarity Type')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\nsns.countplot(data=diamonds, \n              x = 'color', \n              order = diamonds['color'].value_counts(ascending=False).index,\n              palette=sns.color_palette('flare', 10))\nplt.ylabel('# of Sales')\nplt.xlabel('Color')\nplt.grid('both')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\nsns.kdeplot(diamonds, x='price', hue='color', common_norm=False)\nplt.show()\n\n\n\n\n\n\n\nCode\ndiamonds['clarity'].value_counts(ascending=False)\n\n\nclarity\nSI1     13065\nVS2     12258\nSI2      9194\nVS1      8171\nVVS2     5066\nVVS1     3655\nIF       1790\nI1        741\nName: count, dtype: int64\n\n\n\n\nCode\ndiamonds['color'].value_counts(ascending=False)\n\n\ncolor\nG    11292\nE     9797\nF     9542\nH     8304\nD     6775\nI     5422\nJ     2808\nName: count, dtype: int64\n\n\n\n\nCode\ndiamonds['cut'].value_counts(ascending=False)\n\n\ncut\nIdeal        21551\nPremium      13791\nVery Good    12082\nGood          4906\nFair          1610\nName: count, dtype: int64\n\n\n\n\nCode\n# Analyzing distribution of numeric features with histogram plot\nsns.set_theme(style=\"whitegrid\")\ndiamonds.hist(bins=50, figsize=(12, 8))\nplt.show()\n\n\n\n\n\n\n\nCode\ncorr_matrix = diamonds.select_dtypes(np.number).corr()\n\n\n\n\nCode\ncorr_matrix['price'].sort_values(ascending=False)\n\n\nprice    1.000000\ncarat    0.921591\nx        0.884435\ny        0.865421\nz        0.861249\ntable    0.127134\ndepth   -0.010647\nName: price, dtype: float64\n\n\n\n\nCode\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(diamonds[['price', 'carat', 'x', 'y', 'z', 'table', 'depth']], figsize=(15, 10))\nplt.show()\n\n\n\n\n\n\n\nCode\nfrom prettytable import PrettyTable\ndef pretty_printing_function(correlation_name, row_values, column_names):\n    summary_table = PrettyTable()\n    summary_table.title = f\"{correlation_name} Correlation Matrix for the tute1 dataset\"\n    column_names = [f'Feature({chr(0x2193)})/({chr(0x2192)})'] + column_names\n    summary_table.field_names = column_names\n    for i in range(len(row_values)):\n        row_index = column_names[i+1]\n        row_values[i] = [row_index] + row_values[i]\n        summary_table.add_row(row_values[i])\n    print(summary_table)\n\n\ndef calc_pearson_corr(x, y, N):\n    numerator_sum = 0.0; denomnator1_sum = 0.0; denomnator2_sum = 0.0\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    for i in range(N):\n        x_diff = x[i] - x_mean\n        y_diff = y[i] - y_mean\n        numerator_sum += (x_diff * y_diff)\n        denomnator1_sum += np.power(x_diff, 2)\n        denomnator2_sum += np.power(y_diff, 2)\n    pearson_corrcoef = numerator_sum/(np.sqrt(denomnator1_sum)*np.sqrt(denomnator2_sum))\n    return round(pearson_corrcoef, 2)\n\n\ndef calc_partial_corr(x, y, z):\n    r_xy = calc_pearson_corr(x, y, len(diamonds))\n    r_xz = calc_pearson_corr(x, z, len(diamonds))\n    r_yz = calc_pearson_corr(y, z, len(diamonds))\n    partial_corr = (r_xy - (r_xz*r_yz)) / (np.sqrt(1 - r_xz**2) * np.sqrt(1 - r_yz**2))\n    return round(partial_corr, 2)\n\n\ndiamonds_numeric = diamonds.select_dtypes(np.number)\ndef calc_partial_correlation():\n    summary_df = pd.DataFrame(columns = diamonds_numeric.columns, index = diamonds_numeric.columns)\n    for col1 in diamonds_numeric.columns:\n        for col2 in diamonds_numeric.columns:\n            if col1 == col2:\n                summary_df.loc[col1, col2] = 1.0\n            else:\n                other_columns = list(set(diamonds_numeric.columns) - set([col1, col2]))\n                for col3 in other_columns:\n                    summary_df.loc[col1, col2] = calc_partial_corr(diamonds_numeric[col1], diamonds_numeric[col2], diamonds_numeric[col3])\n    pretty_printing_function(\"Partial\", summary_df.values.tolist(), column_names=list(summary_df.columns))\n    return summary_df\n\ncalc_partial_correlation()\n\n\n+-----------------------------------------------------------------------+\n|            Partial Correlation Matrix for the tute1 dataset           |\n+----------------+-------+-------+-------+-------+-------+-------+------+\n| Feature(↓)/(→) | carat | depth | table | price |   x   |   y   |  z   |\n+----------------+-------+-------+-------+-------+-------+-------+------+\n|     carat      |  1.0  | -0.18 |  0.12 |  0.65 |  0.77 |  0.49 | 0.79 |\n|     depth      | -0.18 |  1.0  | -0.32 | -0.17 | -0.48 | -0.37 | 0.19 |\n|     table      |  0.12 | -0.32 |  1.0  |  0.0  |  0.23 |  0.12 | 0.08 |\n|     price      |  0.65 | -0.17 |  0.0  |  1.0  |  0.37 |  0.33 | 0.86 |\n|       x        |  0.77 | -0.48 |  0.23 |  0.37 |  1.0  |  0.64 | 0.88 |\n|       y        |  0.49 | -0.37 |  0.12 |  0.33 |  0.64 |  1.0  | 0.8  |\n|       z        |  0.79 |  0.19 |  0.08 |  0.86 |  0.88 |  0.8  | 1.0  |\n+----------------+-------+-------+-------+-------+-------+-------+------+\n\n\n\n\n\n\n\n\n\ncarat\ndepth\ntable\nprice\nx\ny\nz\n\n\n\n\ncarat\n1.0\n-0.18\n0.12\n0.65\n0.77\n0.49\n0.79\n\n\ndepth\n-0.18\n1.0\n-0.32\n-0.17\n-0.48\n-0.37\n0.19\n\n\ntable\n0.12\n-0.32\n1.0\n0.0\n0.23\n0.12\n0.08\n\n\nprice\n0.65\n-0.17\n0.0\n1.0\n0.37\n0.33\n0.86\n\n\nx\n0.77\n-0.48\n0.23\n0.37\n1.0\n0.64\n0.88\n\n\ny\n0.49\n-0.37\n0.12\n0.33\n0.64\n1.0\n0.8\n\n\nz\n0.79\n0.19\n0.08\n0.86\n0.88\n0.8\n1.0\n\n\n\n\n\n\n\n\n\nCode\ndiamonds.plot(kind=\"scatter\", x=\"price\", y=\"carat\",\n             alpha=0.07, grid=True)\nplt.show()\n\n\n\n\n\n\n\nCode\ndiamonds.shape\ndiamonds.head(10)\n\n\n\n\n\n\n\n\n\ncarat\ncut\ncolor\nclarity\ndepth\ntable\nprice\nx\ny\nz\n\n\n\n\n0\n0.23\nIdeal\nE\nSI2\n61.5\n55.0\n326\n3.95\n3.98\n2.43\n\n\n1\n0.21\nPremium\nE\nSI1\n59.8\n61.0\n326\n3.89\n3.84\n2.31\n\n\n2\n0.23\nGood\nE\nVS1\n56.9\n65.0\n327\n4.05\n4.07\n2.31\n\n\n3\n0.29\nPremium\nI\nVS2\n62.4\n58.0\n334\n4.20\n4.23\n2.63\n\n\n4\n0.31\nGood\nJ\nSI2\n63.3\n58.0\n335\n4.34\n4.35\n2.75\n\n\n5\n0.24\nVery Good\nJ\nVVS2\n62.8\n57.0\n336\n3.94\n3.96\n2.48\n\n\n6\n0.24\nVery Good\nI\nVVS1\n62.3\n57.0\n336\n3.95\n3.98\n2.47\n\n\n7\n0.26\nVery Good\nH\nSI1\n61.9\n55.0\n337\n4.07\n4.11\n2.53\n\n\n8\n0.22\nFair\nE\nVS2\n65.1\n61.0\n337\n3.87\n3.78\n2.49\n\n\n9\n0.23\nVery Good\nH\nVS1\n59.4\n61.0\n338\n4.00\n4.05\n2.39\n\n\n\n\n\n\n\n\n\nCode\n# One-hot encode the categorical variabled before feeding into linear model\nfrom sklearn.preprocessing import OneHotEncoder\n\ndiamonds_cut = diamonds[['cut']]\n\nenc = OneHotEncoder(handle_unknown='ignore')\ndiamonds_cuts_onehot = enc.fit_transform(diamonds_cut)\n\n\n\n\nCode\nenc.categories_\n\n\n[array(['Fair', 'Good', 'Ideal', 'Premium', 'Very Good'], dtype=object)]\n\n\n\n\nCode\nenc.get_feature_names_out()\n\n\narray(['cut_Fair', 'cut_Good', 'cut_Ideal', 'cut_Premium',\n       'cut_Very Good'], dtype=object)\n\n\n\n\nCode\ndiamonds_cuts_onehot.toarray()\n\n\narray([[0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       ...,\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0.]])\n\n\n\n\nCode\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\n\ncategorical_features = ['cut', 'color', 'clarity']\nnumeric_features = ['x', 'y', 'z', 'carat', 'depth', 'table']\n\nnumeric_transformer = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n\npreprocessor = ColumnTransformer(\n    [\n        ('num', numeric_transformer, numeric_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n    ],\n    verbose_feature_names_out=False\n)\n\n\n\n\nCode\ndiamonds_features, diamonds_price = diamonds.loc[:, diamonds.columns != 'price'], diamonds['price']\n\n\n\n\nCode\ndiamonds_features.shape\n\n\n(53940, 9)\n\n\n\n\nCode\ndiamonds_price.shape\n\n\n(53940,)\n\n\n\n\nCode\ndiamonds_features.head()\n\n\n\n\n\n\n\n\n\ncarat\ncut\ncolor\nclarity\ndepth\ntable\nx\ny\nz\n\n\n\n\n0\n0.23\nIdeal\nE\nSI2\n61.5\n55.0\n3.95\n3.98\n2.43\n\n\n1\n0.21\nPremium\nE\nSI1\n59.8\n61.0\n3.89\n3.84\n2.31\n\n\n2\n0.23\nGood\nE\nVS1\n56.9\n65.0\n4.05\n4.07\n2.31\n\n\n3\n0.29\nPremium\nI\nVS2\n62.4\n58.0\n4.20\n4.23\n2.63\n\n\n4\n0.31\nGood\nJ\nSI2\n63.3\n58.0\n4.34\n4.35\n2.75\n\n\n\n\n\n\n\n\n\nCode\nfrom sklearn.model_selection import train_test_split\ndiamonds_features_train, diamonds_features_test, diamonds_price_train, diamonds_price_test = train_test_split(diamonds_features, diamonds_price, test_size=0.25)\n\n#print(diamonds_features_train.head(), diamonds_price_train.head())\n\n\n\n\nCode\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = make_pipeline(preprocessor, LinearRegression())\nlin_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('linearregression', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('linearregression', LinearRegression())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)LinearRegressionLinearRegression()\n\n\n\n\nCode\nlin_reg[:-1].get_feature_names_out()\n\n\narray(['x', 'y', 'z', 'carat', 'depth', 'table', 'cut_Fair', 'cut_Good',\n       'cut_Ideal', 'cut_Premium', 'cut_Very Good', 'color_D', 'color_E',\n       'color_F', 'color_G', 'color_H', 'color_I', 'color_J',\n       'clarity_I1', 'clarity_IF', 'clarity_SI1', 'clarity_SI2',\n       'clarity_VS1', 'clarity_VS2', 'clarity_VVS1', 'clarity_VVS2'],\n      dtype=object)\n\n\n\n\nCode\nlin_reg_input_features = lin_reg[:-1].get_feature_names_out()\npd.Series(lin_reg[-1].coef_.ravel(), index=lin_reg_input_features).plot.bar()\nplt.tight_layout()\n\n\n\n\n\n\n\nCode\ndiamonds_price_predictor = lin_reg.predict(diamonds_features_test)\n\n\n\n\nCode\nlin_reg[-1].coef_\n\n\narray([-1.15234906e+03,  7.85197082e+01, -3.65504992e+01,  5.26242057e+03,\n       -8.91507968e+01, -5.30774984e+01, -1.06221052e+15, -1.06221052e+15,\n       -1.06221052e+15, -1.06221052e+15, -1.06221052e+15, -5.55119485e+14,\n       -5.55119485e+14, -5.55119485e+14, -5.55119485e+14, -5.55119485e+14,\n       -5.55119485e+14, -5.55119485e+14, -3.60092931e+15, -3.60092931e+15,\n       -3.60092931e+15, -3.60092931e+15, -3.60092931e+15, -3.60092931e+15,\n       -3.60092931e+15, -3.60092931e+15])\n\n\n\n\nCode\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, diamonds_price_predictor))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, diamonds_price_predictor))\n\n\nMean Squared Error: 1261730.78\nCoefficient of Determination: 0.92\n\n\n\n\nCode\nfrom sklearn.linear_model import SGDRegressor\n\nsgd_reg = make_pipeline(preprocessor, SGDRegressor(max_iter=1000, tol=1e-5, penalty=None, eta0=0.01, n_iter_no_change=100, random_state=42))\nsgd_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('sgdregressor',\n                 SGDRegressor(n_iter_no_change=100, penalty=None,\n                              random_state=42, tol=1e-05))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('sgdregressor',\n                 SGDRegressor(n_iter_no_change=100, penalty=None,\n                              random_state=42, tol=1e-05))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)SGDRegressorSGDRegressor(n_iter_no_change=100, penalty=None, random_state=42, tol=1e-05)\n\n\n\n\nCode\nprice_predictor_sgd = sgd_reg.predict(diamonds_features_test)\n\n\n\n\nCode\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, price_predictor_sgd))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, price_predictor_sgd))\n\n\nMean Squared Error: 1263241.49\nCoefficient of Determination: 0.92\n\n\n\n\nCode\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr_reg = make_pipeline(preprocessor, RandomForestRegressor())\nrfr_reg.fit(diamonds_features_train, diamonds_price_train)\n\n\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('randomforestregressor', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['x', 'y', 'z', 'carat',\n                                                   'depth', 'table']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['cut', 'color', 'clarity'])],\n                                   verbose_feature_names_out=False)),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['x', 'y', 'z', 'carat', 'depth', 'table']),\n                                ('cat',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['cut', 'color', 'clarity'])],\n                  verbose_feature_names_out=False)num['x', 'y', 'z', 'carat', 'depth', 'table']SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat['cut', 'color', 'clarity']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)RandomForestRegressorRandomForestRegressor()\n\n\n\n\nCode\nprice_predictor_rfr = rfr_reg.predict(diamonds_features_test)\n\n\n\n\nCode\nprint(\"Mean Squared Error: %.2f\" % mean_squared_error(diamonds_price_test, price_predictor_rfr))\nprint(\"Coefficient of Determination: %.2f\" % r2_score(diamonds_price_test, price_predictor_rfr))\n\n\nMean Squared Error: 317507.25\nCoefficient of Determination: 0.98\n\n\n\n\n\n Back to top"
  }
]