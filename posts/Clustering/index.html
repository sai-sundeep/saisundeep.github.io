<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sai Sundeep Rayidi">
<meta name="dcterms.date" content="2023-11-29">

<title>Sai’s ML blog - Unsupervised Learning: Clustering Using K-Means and Gaussian Mixture Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Sai’s ML blog - Unsupervised Learning: Clustering Using K-Means and Gaussian Mixture Models">
<meta property="og:description" content="">
<meta property="og:image" content="https://sai-sundeep.github.io/saisundeep.github.io/posts/Clustering/clustering.png">
<meta property="og:site-name" content="Sai's ML blog">
<meta property="og:image:height" content="576">
<meta property="og:image:width" content="1024">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Sai’s ML blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/sai-sundeep/sai-sundeep" rel="" target="">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/issues" rel="" target="">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/sai-sundeep-rayidi-7256b4245/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Unsupervised Learning: Clustering Using K-Means and Gaussian Mixture Models</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">clustering</div>
                <div class="quarto-category">analysis</div>
                <div class="quarto-category">visualization</div>
                <div class="quarto-category">K-Means</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Sai Sundeep Rayidi </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 29, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>So far we have seen regression and classification algorithms and their many variants. In this blog, we will be exploring another type of learning called Unsupervised Learning. Unlike in regression and classification where we have response variable or target classes, we will not have any predefined labels in unsupervised learning. It is up for the algorithm to learn the similarities and differences and then group the instances that belong together. We will be working with the <strong>Penguins</strong> dataset in this blog to perform unsupervised learning. At a high level, we will -</p>
<ul>
<li>Import and Analyze Penguins dataset</li>
<li>Perform <strong>K-Means</strong> Clustering</li>
<li>Evaluating K-Means Performance and Choosing Optimal Number of Clusters-
<ul>
<li>Inertia</li>
<li>Silhouette Score</li>
</ul></li>
<li>Gaussian Mixture Models</li>
</ul>
<section id="import-and-analyze-penguins-dataset" class="level2">
<h2 class="anchored" data-anchor-id="import-and-analyze-penguins-dataset">1. Import and Analyze Penguins Dataset</h2>
<p>The penguins dataset is available in the seaborn visualization package. Let’s load the dataset and analyze its features and instances.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T13:22:27.366216300Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T13:22:27.334241700Z&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>penguins <span class="op">=</span> sns.load_dataset(<span class="st">'penguins'</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of Features: </span><span class="sc">{</span>penguins<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of Observations: </span><span class="sc">{</span>penguins<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Features - </span><span class="sc">{</span><span class="bu">list</span>(penguins.columns)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of Features: 344
Number of Observations: 7
Features - ['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']</code></pre>
</div>
</div>
<p>Let us see unique species, islands from the penguins dataset and also the range of values of the numerical features take using pandas describe method. Let us also ensure the dataset is free from any nulls or missing values (NaN) by calculating the percentage of Nulls or NaNs in each column.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T13:22:30.249085900Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T13:22:30.170485600Z&quot;}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Unique colors: </span><span class="sc">{</span>penguins[<span class="st">'species'</span>]<span class="sc">.</span>unique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Unique cut type: </span><span class="sc">{</span>penguins[<span class="st">'island'</span>]<span class="sc">.</span>unique()<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(penguins.describe(), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>percent_missing <span class="op">=</span> ((penguins.isnull().<span class="bu">sum</span>() <span class="op">+</span> penguins.isna().<span class="bu">sum</span>()) <span class="op">/</span> <span class="bu">len</span>(penguins)) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>missing_values_percent_df <span class="op">=</span> percent_missing.to_frame(<span class="st">'Missing Data Percent'</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(missing_values_percent_df.<span class="bu">round</span>(<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unique colors: ['Adelie' 'Chinstrap' 'Gentoo']
Unique cut type: ['Torgersen' 'Biscoe' 'Dream']

       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g
count      342.000000     342.000000         342.000000   342.000000
mean        43.921930      17.151170         200.915205  4201.754386
std          5.459584       1.974793          14.061714   801.954536
min         32.100000      13.100000         172.000000  2700.000000
25%         39.225000      15.600000         190.000000  3550.000000
50%         44.450000      17.300000         197.000000  4050.000000
75%         48.500000      18.700000         213.000000  4750.000000
max         59.600000      21.500000         231.000000  6300.000000 

                   Missing Data Percent
species                            0.00
island                             0.00
bill_length_mm                     1.16
bill_depth_mm                      1.16
flipper_length_mm                  1.16
body_mass_g                        1.16
sex                                6.40</code></pre>
</div>
</div>
<p>We do have missing or null values in five of the columns. Because this is a very small percentage, lets us drop these records.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T13:22:32.642428700Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T13:22:32.627914600Z&quot;}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>penguins.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataset Shaper After Removing Nulls: </span><span class="sc">{</span>penguins<span class="sc">.</span>shape<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>percent_missing <span class="op">=</span> ((penguins.isnull().<span class="bu">sum</span>() <span class="op">+</span> penguins.isna().<span class="bu">sum</span>()) <span class="op">/</span> <span class="bu">len</span>(penguins)) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>missing_values_percent_df <span class="op">=</span> percent_missing.to_frame(<span class="st">'Missing Data Percent'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(missing_values_percent_df.<span class="bu">round</span>(<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset Shaper After Removing Nulls: (333, 7)

                   Missing Data Percent
species                             0.0
island                              0.0
bill_length_mm                      0.0
bill_depth_mm                       0.0
flipper_length_mm                   0.0
body_mass_g                         0.0
sex                                 0.0</code></pre>
</div>
</div>
<p>!Perfect. We now have cleaned the dataset from Nulls and NaNs.</p>
<p>Let us now visualize the features bill_length, bill_depth, and flipper_length using a scatterplot. For this you can use the pandas inbuilt scattermatrix plot. But using Seaborn helps us to add hue, using species labels. This helps us better differentiate the underlying clusters in our dataset.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T13:22:36.813393500Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T13:22:36.406419600Z&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>] <span class="op">=</span> sns.scatterplot(penguins, x<span class="op">=</span><span class="st">'bill_length_mm'</span>, y<span class="op">=</span><span class="st">'bill_depth_mm'</span>, hue<span class="op">=</span><span class="st">'species'</span>, ax<span class="op">=</span>axs[<span class="dv">0</span>])</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>] <span class="op">=</span> sns.scatterplot(penguins, x<span class="op">=</span><span class="st">'flipper_length_mm'</span>, y<span class="op">=</span><span class="st">'bill_length_mm'</span>, hue<span class="op">=</span><span class="st">'species'</span>, ax<span class="op">=</span>axs[<span class="dv">1</span>])</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-5-output-1.png" width="808" height="503"></p>
</div>
</div>
<p>Looks like our data does have an underlying clusters and we seem to have three clusters one for each species type - Adelie, Gentoo, and Chinstrap. We can now apply K-Means clustering.</p>
</section>
<section id="apply-k-means-clustering" class="level2">
<h2 class="anchored" data-anchor-id="apply-k-means-clustering">2. Apply K-Means Clustering</h2>
<p>K-means is an unsupervised learning algorithm that is capable of clustering a given dataset of instances quickly and efficiently into K clusters. It works by assigning K random instances as centroids to K clusters and then assign remaining instances as the members to a cluster that it is nearest to. It calculates the distance using the <strong>mean squared distance</strong> between the instances and their closest centroids. It then calculates the centroids using the newly formed clusters. And then the instances are re-assigned after computing the distance to newly formed clusters. This process continues until there is no further shift in centroids. To put it formally, the objective at each step is to minimize the following within-cluster sum of squares distance-</p>
<p><span class="math display">\[ {\displaystyle \mathop {\operatorname {arg\,min} } _{\mathbf {S} }\sum _{i=1}^{k}\sum _{\mathbf {x} \in S_{i}}\left\|\mathbf {x} -{\boldsymbol {\mu }}_{i}\right\|^{2}=\mathop {\operatorname {arg\,min} } _{\mathbf {S} }\sum _{i=1}^{k}|S_{i}|\operatorname {Var} S_{i}} \]</span></p>
<p>where, <span class="math inline">\(x_i\)</span> denote the n observations in the dataset <span class="math inline">\(x_1, x_2, x_3, ..., x_n\)</span> <span class="math inline">\(S_i = {S_1, S_2, S_3, ..., S_k}\)</span> denote the k sets/clusters <span class="math inline">\(\mu_i\)</span> is the mean or centroid of the points in <span class="math inline">\(S_i\)</span></p>
<p>Before we start applying K-means on penguins dataset, a couple of things to take care of. We need to scale our features. Clustering algorithms are sensitive to scale and Scaling ensures that all features in the data are weighted equally. This is very important because clustering algorithms use distance between data points to assess the similarity between them. A simple way to do this is transforming the features into their Z-scores.</p>
<p><span class="math display">\[ z={x-\mu  \over \sigma } \]</span></p>
<p>We can simply pass the features to scikit-learns StandardScalar to do the same.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T13:23:05.967683400Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T13:23:05.710730100Z&quot;}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>penguins_numerical_features <span class="op">=</span> penguins.select_dtypes(include<span class="op">=</span>np.number)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>penguins_scaled <span class="op">=</span> scaler.fit_transform(penguins_numerical_features)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>penguins_scaled_df <span class="op">=</span> pd.DataFrame(penguins_scaled, columns<span class="op">=</span>penguins_numerical_features.columns, index<span class="op">=</span><span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Great! our features are scaled. Now lets feed them to the K-Means algorithm to see if it can figure out the clusters in our dataset that we have found earlier. Let us set the initial number of clusters to be 3 because we know there to be three different species in our dataset. Initializing with correct number of clusters is not always possible, but in this case we have the ground truth, so we can use that to initialize k.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T16:56:44.354248300Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T16:56:44.011878500Z&quot;}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="im">as</span> mpl</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>n_clusters <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">3</span>, svd_solver<span class="op">=</span><span class="st">'full'</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>penguins_reduced <span class="op">=</span> pca.fit_transform(penguins_scaled_df)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Cumulative Explained Variance (%): ", np.cumsum(pca.explained_variance_ratio_ * 100).round(2))</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(init<span class="op">=</span><span class="st">"k-means++"</span>, n_clusters<span class="op">=</span><span class="dv">3</span>, n_init<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>kmeans.fit(penguins_reduced)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>k_means_cluster_centers <span class="op">=</span> kmeans.cluster_centers_</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The Cluster Centers are - </span><span class="ch">\n</span><span class="sc">{</span>k_means_cluster_centers<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># PC1 &amp; PC2</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    penguins_reduced, </span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">'PC1'</span>, <span class="st">'PC2'</span>, <span class="st">'PC3'</span>]</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>).plot.scatter(</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="dv">0</span>, y<span class="op">=</span><span class="dv">1</span>, c<span class="op">=</span>kmeans.labels_, cmap<span class="op">=</span><span class="st">'viridis'</span>, colorbar<span class="op">=</span><span class="va">False</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=-</span><span class="fl">0.39</span>, y<span class="op">=</span><span class="fl">1.103</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=-</span><span class="fl">0.39</span>, y<span class="op">=</span><span class="fl">1.103</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'w'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=</span><span class="fl">2.01</span>, y<span class="op">=-</span><span class="fl">0.394</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=</span><span class="fl">2.01</span>, y<span class="op">=-</span><span class="fl">0.394</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'w'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=-</span><span class="fl">1.5</span>, y<span class="op">=-</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=-</span><span class="fl">1.5</span>, y<span class="op">=-</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'w'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Scatter plot of Reduced Data - PCA1 vs PCA2"</span>)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="co"># PC1 &amp; PC3</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>    penguins_reduced, </span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">'PC1'</span>, <span class="st">'PC2'</span>, <span class="st">'PC3'</span>]</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>).plot.scatter(</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="dv">0</span>, y<span class="op">=</span><span class="dv">2</span>, c<span class="op">=</span>kmeans.labels_, cmap<span class="op">=</span><span class="st">'viridis'</span>, colorbar<span class="op">=</span><span class="va">False</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=-</span><span class="fl">0.39</span>, y<span class="op">=</span><span class="fl">0.384</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=-</span><span class="fl">0.39</span>, y<span class="op">=</span><span class="fl">0.384</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'w'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=</span><span class="fl">2.01</span>, y<span class="op">=-</span><span class="fl">0.035</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=</span><span class="fl">2.01</span>, y<span class="op">=-</span><span class="fl">0.035</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'w'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=-</span><span class="fl">1.5</span>, y<span class="op">=-</span><span class="fl">0.22</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=-</span><span class="fl">1.5</span>, y<span class="op">=-</span><span class="fl">0.22</span>, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'w'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Scatter plot of Reduced Data - PCA1 vs PCA3"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The Cluster Centers are - 
[[-1.58950101 -0.3000391  -0.2218791 ]
 [ 2.01297608 -0.39402785 -0.03586763]
 [-0.39177408  1.02255234  0.3941968 ]]</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>Text(0.5, 1.0, 'Scatter plot of Reduced Data - PCA1 vs PCA3')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-7-output-3.png" width="587" height="449"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-7-output-4.png" width="587" height="449"></p>
</div>
</div>
<p>The k-means algorithm was able to create three clusters and assign the instances to these three clusters. As we can see from the above plot, the clusters on the left have some instances overlapping and there is no clear decision boundary. Let us now evaluate this model’s performance.</p>
</section>
<section id="evaluating-k-means-performance-and-choosing-optimal-number-of-clusters" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-k-means-performance-and-choosing-optimal-number-of-clusters">Evaluating K-Means Performance and Choosing Optimal Number of Clusters</h2>
<section id="inertia-elbow-curve" class="level3">
<h3 class="anchored" data-anchor-id="inertia-elbow-curve">3.1 Inertia &amp; Elbow Curve</h3>
<p>One way to initialize the number of clusters is to run a clustering algorithm and know what could be the approximate number of clusters. Anathor approach is to run the algorithm multiple times using different values for k, in scikit-learn KMeans this is controlled by n_init hyperparameter. At each random initialization some performance metric is calculated and the model with best performance is retained. For K-Means this metric is the model’s <strong>inertia</strong>. It is calculated by summing the squared distances between each data point and its closest centroid. As you would guess, lower the inertia of the model, better the clustering. Scikit-learn also provides score() method, which is negative of the inertia. Higher the score value (closer to zero) better the performance.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T15:08:10.402774300Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T15:08:10.336585700Z&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Inertia: "</span>, kmeans.inertia_)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Score: "</span>, kmeans.score(penguins_reduced))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Inertia:  334.92198044554704
Score:  -334.92198044554704</code></pre>
</div>
</div>
<p>The scores does not look so good even with a good initialization of n_clusters=3. This has to do with <strong>Clusters of varying sizes and density.</strong> k-means has trouble clustering data where clusters are of varying sizes and density. To see the inertia of the model initialized with different values of k, we can make use of the <strong>elbow curve</strong> as shown below. As we can see, the kmeans algorithm gives better performance with k greater than 3 (lower inertia). Which as we know is not correct. So inertia is not always perfect measure of the models performance.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T15:17:46.617196700Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T15:17:45.795311800Z&quot;}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>kmeans_per_k <span class="op">=</span> [KMeans(n_clusters<span class="op">=</span>k, n_init<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit(penguins_reduced)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>)]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>inertias <span class="op">=</span> [model.inertia_ <span class="cf">for</span> model <span class="kw">in</span> kmeans_per_k]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="fl">3.5</span>))</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>), inertias, <span class="st">"bo-"</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"$k$"</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Inertia"</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>plt.axis([<span class="dv">1</span>, <span class="fl">8.5</span>, <span class="dv">0</span>, <span class="dv">1500</span>])</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="st">'both'</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-9-output-1.png" width="676" height="319"></p>
</div>
</div>
</section>
<section id="silhouette-score" class="level3">
<h3 class="anchored" data-anchor-id="silhouette-score">3.2 Silhouette Score</h3>
<p>A more precise but computationally expensive metric is the model’s <em>Silhouette Score</em> which is calculated as the mean <em>silhouette coefficient</em> over all the instances. An instance’s silhouette coefficient is calculated as <span class="math inline">\((b-a)/max(a, b)\)</span>, where a is the mean distances to other instances in the same cluster and b is the mean distance to the instances of the next closest cluster. The silhouette coefficient can vary between –1 and +1. A coefficient close to +1 means that the instance is well inside its own cluster and far from other clusters, while a coefficient close to 0 means that it is close to a cluster boundary; finally, a coefficient close to –1 means that the instance may have been assigned to the wrong cluster.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T15:30:22.275140700Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T15:30:22.180169400Z&quot;}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>silhouette_score(penguins_reduced, kmeans.labels_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>0.47266490077361456</code></pre>
</div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T15:32:01.884939800Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T15:32:01.766276900Z&quot;}" data-execution_count="10">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>silhouette_scores <span class="op">=</span> [silhouette_score(penguins_reduced, model.labels_)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>                     <span class="cf">for</span> model <span class="kw">in</span> kmeans_per_k[<span class="dv">1</span>:]]</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">3</span>))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">10</span>), silhouette_scores, <span class="st">"bo-"</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"$k$"</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Silhouette score"</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.axis([1.8, 8.5, 0.55, 0.7])</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="st">'both'</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-11-output-1.png" width="672" height="282"></p>
</div>
</div>
<p>Once again, we can see that for k greater than 3, the silhoutte score is getting closer to 0. Which suggests more instances are close to the cluster boundary. We need a better methodology to cluster our dataset.</p>
</section>
</section>
<section id="gaussian-mixture-models" class="level2">
<h2 class="anchored" data-anchor-id="gaussian-mixture-models">4. Gaussian Mixture Models</h2>
<p>The Gaussian Mixture Model is a probabilistic model that assumes that instances are drawn from multiple but finite number of Gaussian (normal) distributions whose parameters are unknown. Typically, all the instances generated from a single Gaussian distribution form an elliptical shaped cluster. There are several variations to <a href="https://scikit-learn.org/stable/modules/mixture.html">Gaussian Mixture Models</a>. The one we will implement using scikit-learn is the GaussianMixture which requires us to know the number of clusters (k) in advance. Usually, it is a good idea to run kmeans or mini-batch kmeans to help with figuring the optimum value for k. Given a dataset X, the GaussianMixture works as follows -</p>
<ul>
<li>For each instance in <strong>X</strong>, a cluster is randomly picked among <em>k</em> clusters. The probability of choosing a cluster <span class="math inline">\(j\)</span> is given by clusters weight <span class="math inline">\(\theta(j)\)</span> and the index of the cluster choosen for instance <em>i</em> is noted by <span class="math inline">\(Z(i)\)</span>.</li>
<li>If instance <em>i</em> is assigned to cluster <em>j</em> i.e., <span class="math inline">\(Z(i) = j\)</span>, then the location of this instance is sampled randomly from the Gaussian Distribution with <span class="math inline">\(\mu(j)\)</span> and covariance matrix <span class="math inline">\(\Sigma(j)\)</span>. This is noted by <span class="math inline">\(x(i) \sim \Nu(\mu(j), \Sigma(j))\)</span></li>
</ul>
<p>GMMs are particularly useful when the data is not clearly separable into distinct clusters. We may be able to solve our problem with the cluster overlapping that we have seen with k-means clustering. Let us apply the GaussianMixture algorithm to our Penguins dataset. Let us set n_components and run the algorithm for 10 iterations.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T19:12:33.471211900Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T19:12:33.368140800Z&quot;}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>gm <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">3</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>y_labels <span class="op">=</span> gm.fit_predict(penguins_reduced)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can ectract the weights of the clusters formed by the GaussianMixtures algorithm and compare it with the weights of the raw dataset.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T19:27:55.601120100Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T19:27:55.538163Z&quot;}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>model_weights <span class="op">=</span> (gm.weights_ <span class="op">*</span> <span class="dv">100</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>raw_weights <span class="op">=</span> ((penguins[<span class="st">'species'</span>].value_counts() <span class="op">/</span> <span class="bu">len</span>(penguins)) <span class="op">*</span> <span class="dv">100</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Weights of Clusters formed by GMM: </span><span class="ch">\n\t\t</span><span class="ss"> </span><span class="sc">{</span>model_weights<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Weights of Clusters from Raw Data: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>raw_weights<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Weights of Clusters formed by GMM: 
         [35.74 44.32 19.94]

Weights of Clusters from Raw Data: 
 species
Adelie       43.84
Gentoo       35.74
Chinstrap    20.42
Name: count, dtype: float64</code></pre>
</div>
</div>
<p>Great! Our model is able to predict three clusters and the weights also look pretty close to percentage of different species we have in our dataset. Furthermore, the cluster centroids and the corresponding covariance matrices can be extracted using means_ and covariances_ parameters.</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T19:34:13.152379200Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T19:34:13.136327500Z&quot;}" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cluster Centroids: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>(gm.means_)<span class="sc">.</span><span class="bu">round</span>(<span class="dv">3</span>)<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Covariance Matrix for each corresponding distribution: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>(gm.covariances_)<span class="sc">.</span><span class="bu">round</span>(<span class="dv">3</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cluster Centroids: 
 [[ 2.013 -0.394 -0.036]
 [-1.468 -0.15  -0.292]
 [-0.344  1.039  0.714]]

Covariance Matrix for each corresponding distribution: 
 [[[ 0.394  0.372 -0.159]
  [ 0.372  0.504 -0.176]
  [-0.159 -0.176  0.196]]

 [[ 0.28   0.173 -0.087]
  [ 0.173  0.472 -0.203]
  [-0.087 -0.203  0.265]]

 [[ 0.267  0.241 -0.1  ]
  [ 0.241  0.54  -0.096]
  [-0.1   -0.096  0.208]]]</code></pre>
</div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2023-11-29T19:44:59.008190800Z&quot;,&quot;start_time&quot;:&quot;2023-11-29T19:44:58.882140800Z&quot;}" data-execution_count="14">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(penguins_reduced[:, <span class="dv">0</span>], penguins_reduced[:, <span class="dv">2</span>], c<span class="op">=</span>y_labels)    </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):    </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    plt.scatter(x<span class="op">=</span>gm.means_[i][<span class="dv">0</span>], y<span class="op">=</span>gm.means_[i][<span class="dv">2</span>], s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'b'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    plt.scatter(x<span class="op">=</span>gm.means_[i][<span class="dv">0</span>], y<span class="op">=</span>gm.means_[i][<span class="dv">2</span>], s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'w'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Penguins Dataset Clustered using Gaussian Mixture Model"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r'$x_1$'</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r'$x_3$'</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-15-output-1.png" width="587" height="449"></p>
</div>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Unsupervised learning is an amazing and useful technique that can be used to discover hidden patterns and structures in data without the need for labeled examples. We have learned about Clustering and the most widely used and easy to implement K-Means Clustering. We learned that K-Means has some limitations and it is usually a good idea to start with k-means of one of its variants before trying out advanced clustering algorithms like DBSCAN or Gaussian Mixture Models. We have also seen how Gaussian Mixtures work and how to use them to train on data that has clusters closely packed and inseparable by other algorithms.</p>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2023, Sai Sundeep Rayidi</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/sai-sundeep/sai-sundeep">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/sai-sundeep-rayidi-7256b4245/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>